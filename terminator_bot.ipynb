{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Install packages"
      ],
      "metadata": {
        "id": "AIjCgaAz7VQO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries"
      ],
      "metadata": {
        "id": "8nCpIYs_tFDh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVYh0CPxnJCP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e056be6-93ef-4247-acd6-0e982ff50fca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "import matplotlib\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from nltk import word_tokenize\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml"
      ],
      "metadata": {
        "id": "07PEApLx8DOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get data from GitHub"
      ],
      "metadata": {
        "id": "4wzKtbvawd5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_url = 'https://raw.githubusercontent.com/davisjrule/SQuAD-bot/main/train-squad.csv'\n",
        "df = pd.read_csv(csv_url)\n",
        "df.drop('id', axis=1, inplace=True)\n",
        "df.drop('answer_start', axis=1, inplace=True)\n",
        "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "df.drop('context', axis=1, inplace=True)\n",
        "\n",
        "df.head()\n",
        "\n",
        "#df.iloc[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MFrRVFWBwAnh",
        "outputId": "437b0fa6-17ed-4ce9-a10d-b545c48d04df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question                 text\n",
              "0           When did Beyonce start becoming popular?    in the late 1990s\n",
              "1  What areas did Beyonce compete in when she was...  singing and dancing\n",
              "2  When did Beyonce leave Destiny's Child and bec...                 2003\n",
              "3      In what city and state did Beyonce  grow up?        Houston, Texas\n",
              "4         In which decade did Beyonce become famous?           late 1990s"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f6054a8d-3780-44fd-a62d-37a31b146020\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>When did Beyonce start becoming popular?</td>\n",
              "      <td>in the late 1990s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What areas did Beyonce compete in when she was...</td>\n",
              "      <td>singing and dancing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
              "      <td>2003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In what city and state did Beyonce  grow up?</td>\n",
              "      <td>Houston, Texas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In which decade did Beyonce become famous?</td>\n",
              "      <td>late 1990s</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6054a8d-3780-44fd-a62d-37a31b146020')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f6054a8d-3780-44fd-a62d-37a31b146020 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f6054a8d-3780-44fd-a62d-37a31b146020');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('ai.yml', 'r') as file:\n",
        "    data = yaml.safe_load(file)\n",
        "\n",
        "df = pd.DataFrame(data = data['conversations'])\n",
        "df"
      ],
      "metadata": {
        "id": "Rj_qrjcX8BGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process data"
      ],
      "metadata": {
        "id": "RGu4A2pNtPbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "  text = str(text).lower()\n",
        "  text = text.replace(\"can't\", \"cannot\")\n",
        "  text = text.replace(\"won't\", \"will not\")\n",
        "  text = text.replace(\"i'm\", \"i am\")\n",
        "  text = text.replace(\"'ve\", \" have\")\n",
        "  text = text.replace(\"'ll\", \" will\")\n",
        "  text = text.replace(\"n't\", \" not\")\n",
        "  text = text.replace(\"'d\", \" would\")\n",
        "  text = text.replace(\"'s\", \" is\")\n",
        "  text = text.replace(\"'re\", \" are\")\n",
        "  for char in string.punctuation:\n",
        "    if char != '-':\n",
        "      text = text.replace(char, '')\n",
        "  return text"
      ],
      "metadata": {
        "id": "y1nb4dDMqo8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = list(zip(df['question'],df['text']))\n",
        "# pairs\n"
      ],
      "metadata": {
        "id": "ccSxAhPN6jH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "\n",
        "input_docs = []\n",
        "target_docs = []\n",
        "input_tokens = set()\n",
        "target_tokens = set()\n",
        "\n",
        "for line in pairs[:6000]:\n",
        "  input_doc, target_doc = line[0], line[1]\n",
        "\n",
        "  input_doc = clean_text(input_doc)\n",
        "  target_doc = clean_text(target_doc)\n",
        "\n",
        "  # Appending each input sentence to input_docs\n",
        "  input_docs.append(input_doc)\n",
        "  \n",
        "  # Splitting words from punctuation  \n",
        "  target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n",
        "\n",
        "  # Redefine target_doc below and append it to target_docs\n",
        "  target_doc = '<START> ' + target_doc + ' <END>'\n",
        "  target_docs.append(target_doc)\n",
        "\n",
        "  \n",
        "  # Now we split up each sentence into words and add each unique word to our vocabulary set\n",
        "  for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n",
        "    if token not in input_tokens:\n",
        "      input_tokens.add(token)\n",
        "       \n",
        "  for token in target_doc.split():\n",
        "    if token not in target_tokens:\n",
        "      target_tokens.add(token)\n",
        "\n",
        "\n",
        "input_tokens = sorted(list(input_tokens))\n",
        "target_tokens = sorted(list(target_tokens))\n",
        "num_encoder_tokens = len(input_tokens)\n",
        "num_decoder_tokens = len(target_tokens)\n",
        "\n",
        "# target_tokens"
      ],
      "metadata": {
        "id": "C4E_ZvCh5Iiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30wb6DfQG2-g",
        "outputId": "5aa1d695-bd29-47ca-8f02-5bb22491da5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['-', '00', '007', '05', '06', '08', '1', '10', '100', '1000', '10000', '100000000', '100m', '10217', '107', '11', '110th', '12', '120000', '121', '1260', '1294', '13', '14', '146', '15', '1573', '158', '1587', '16', '1600s', '1609', '1616', '1653', '1664', '1673', '1674', '17', '1700', '1700s', '1713', '1730', '1765', '1776', '1785', '1790', '18', '1806', '1811', '1817', '1818', '1820s', '1824', '1825', '1826', '1827', '1828', '1829', '1830', '1831', '1832', '1833', '1834', '1835', '1836', '1837', '1838', '1839', '1840', '1841', '1842', '1843', '1844', '1845', '1846', '1847', '1848', '1849', '1855', '1857', '1860', '1860s', '1861', '1863', '1865', '1870', '1880s', '1890', '1890s', '1892', '1897', '18th', '19', '1900', '1909', '1910', '1911', '1915', '1920s', '1924', '1928', '1930s', '1937', '1940', '1940s', '1942', '1945', '1950s', '1952', '1957', '1961', '1962', '1965', '1966', '1968', '1970s', '1980s', '1981', '1987', '1990', '1990s', '1991', '1992', '1993', '1995', '1997', '1999', '19th', '1q08', '2', '20', '200', '2000', '200000', '2000s', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '200m', '200th', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2050', '20th', '21', '21st', '22', '2212016', '2215', '23', '24', '25', '26', '27', '27th', '28', '29', '3', '30', '330', '35', '3rd', '4', '40', '4040', '43', '450', '46th', '488', '49', '4th', '5', '50', '500', '500th', '50s', '52nd', '535', '57th', '58', '5g', '5th', '6', '60', '60s', '63', '64', '66', '660', '6th', '7', '70', '72', '7210', '73', '74', '8', '80', '808s', '847', '8th', '9', '90', '900', '9050', '911', '95', 'a', 'aac', 'abandon', 'abbreviation', 'abc', 'abdul', 'abhidhamma', 'abhidharma', 'ability', 'able', 'abodes', 'abolished', 'abolition', 'aboolian', 'about', 'aboutcom', 'above', 'abrams', 'absence', 'absorb', 'absorbed', 'absorbs', 'absorption', 'abstract', 'abusive', 'academy', 'acadian', 'accelerator', 'accept', 'acceptance', 'accepted', 'access', 'accessed', 'accessible', 'accessories', 'accessory', 'accident', 'accidental', 'acclaim', 'acclaimed', 'acclimation', 'accolade', 'accolades', 'accommodate', 'accompanied', 'accomplished', 'according', 'account', 'accounted', 'accounting', 'accounts', 'accusations', 'accuse', 'accused', 'accuses', 'ace', 'ached', 'achieve', 'achieved', 'achieving', 'acient', 'acknowledging', 'acoustic', 'acquainted', 'acquire', 'acquired', 'acquires', 'acquiring', 'acquittal', 'acres', 'acronym', 'across', 'act', 'acting', 'action', 'actions', 'active', 'activities', 'activity', 'actor', 'actors', 'actress', 'acts', 'actual', 'actually', 'adam', 'adams', 'adaptation', 'adapting', 'add', 'added', 'addiction', 'adding', 'addition', 'additional', 'address', 'addressed', 'adds', 'adhere', 'adherence', 'adherents', 'adichie', 'adidas', 'adjacent', 'adjective', 'adjusted', 'administers', 'administrative', 'admire', 'admitted', 'admitting', 'adolphe', 'adopt', 'adopted', 'adult', 'adults', 'advanced', 'advantage', 'advertised', 'advertisement', 'advertisements', 'advertising', 'advetisments', 'advise', 'adviser', 'aerial', 'aesthetic', 'affair', 'affairs', 'affect', 'affected', 'affecting', 'affection', 'affiliations', 'affirmed', 'affixed', 'afflictions', 'affluent', 'african', 'africans', 'after', 'aftershock', 'aftershocks', 'again', 'against', 'age', 'agencies', 'agency', 'aggression', 'agnostics', 'agonizing', 'agree', 'agreed', 'agreement', 'agriculture', 'ahead', 'ai', 'aia', 'aid', 'aided', 'aids', 'aiken', 'ailment', 'aim', 'aimed', 'air', 'aircraft', 'aired', 'airing', 'airlifted', 'airlines', 'airport', 'airports', 'airtrain', 'akiko', 'aksobhya', 'al', 'alabama', 'alaina', 'alarm', 'albanians', 'albert', 'album', 'albums', 'alert', 'alexander', 'alexandria', 'alexis', 'algae', 'ali', 'alice', 'aliens', 'alive', 'all', 'allegedly', 'allen', 'alleviation', 'alley', 'alliance', 'allocated', 'allow', 'allowed', 'allowing', 'allows', 'almost', 'alone', 'along', 'alongside', 'alpha', 'already', 'also', 'altan', 'alter', 'altercation', 'altered', 'alternate', 'alternative', 'although', 'altitude', 'always', 'alyssa', 'ama', 'amas', 'amateur', 'ambedkar', 'amber', 'ambushes', 'amdo', 'america', 'american', 'americana', 'americans', 'amiibo', 'amitabha', 'amity', 'ammonia', 'among', 'amount', 'amounts', 'ampitheatre', 'amsasha', 'amsterdam', 'amtrak', 'amy', 'an', 'analogous', 'analysis', 'analyzing', 'ananda', 'anapanasati', 'anatta', 'ancestry', 'ancient', 'and', 'anderson', 'angela', 'angeles', 'angels', 'animal', 'animals', 'animated', 'animosity', 'annex', 'anniversary', 'annouce', 'annouced', 'announce', 'announced', 'announcing', 'annual', 'annually', 'anonymously', 'another', 'answer', 'anthem', 'anthonio', 'anti', 'antiques', 'antitrypsin', 'antoni', 'anxian', 'anxiety', 'any', 'anyone', 'aonuma', 'apartment', 'apartments', 'apathy', 'apologize', 'apologized', 'apology', 'apoloizing', 'app', 'apparel', 'apparent', 'appeal', 'appealing', 'appear', 'appearance', 'appeared', 'appellate', 'apple', 'apples', 'application', 'applications', 'applied', 'apply', 'appoint', 'appointed', 'approach', 'approval', 'approximate', 'approximately', 'apps', 'apread', 'april', 'arabia', 'arahant', 'arahants', 'arcadian', 'archery', 'archie', 'architectural', 'architecture', 'archuletta', 'are', 'area', 'areas', 'arena', 'argued', 'argument', 'arise', 'arises', 'arising', 'armani', 'armed', 'armstrong', 'army', 'arnold', 'arose', 'around', 'arranged', 'arrangement', 'arrangements', 'arrest', 'arrested', 'arrive', 'arrived', 'arriving', 'arrow', 'arrows', 'art', 'arthur', 'article', 'artist', 'artistic', 'artists', 'arts', 'arupyadhatu', 'as', 'ascribed', 'asia', 'asian', 'aside', 'asita', 'ask', 'asked', 'asking', 'asoka', 'aspect', 'aspects', 'aspire', 'aspires', 'aspiro', 'assassin', 'assault', 'asserted', 'assertion', 'assertions', 'assess', 'assessed', 'assets', 'assigned', 'assist', 'assistance', 'assistant', 'assists', 'associated', 'association', 'assume', 'assure', 'astasahasrika', 'astoria', 'astrologer', 'at', 'athletic', 'atlantic', 'atmosphere', 'atmospheric', 'atomists', 'attachment', 'attack', 'attacked', 'attacking', 'attacks', 'attain', 'attained', 'attainment', 'attempt', 'attempted', 'attempts', 'attend', 'attendance', 'attendant', 'attended', 'attention', 'atticus', 'attitude', 'attorney', 'attracted', 'attribute', 'attributed', 'atwood', 'audience', 'audiences', 'audio', 'audition', 'auditioned', 'auditions', 'auditor', 'aug', 'august', 'auguste', 'austin', 'australia', 'australian', 'austria', 'austrian', 'authentic', 'author', 'authorities', 'authority', 'authorized', 'authors', 'auto', 'automobile', 'automobiles', 'av', 'availability', 'available', 'availablity', 'availalbe', 'avenue', 'average', 'averaged', 'aversion', 'aviation', 'avidya', 'avoid', 'avoidance', 'awaken', 'awakened', 'awakening', 'award', 'awarded', 'awards', 'aware', 'away', 'ayurbarwada', 'b', 'babasaheb', 'baby', 'bacame', 'bach', 'back', 'background', 'backing', 'backup', 'bad', 'bail', 'baker', 'balance', 'ball', 'ballades', 'ballet', 'balloon', 'balloons', 'ballot', 'ballroom', 'ballrooms', 'ban', 'band', 'bangladesh', 'bangs', 'banking', 'banks', 'baptised', 'baptismal', 'bar', 'barack', 'barcelona', 'bardo', 'barely', 'barrie', 'barrier', 'barrino', 'base', 'baseball', 'based', 'basic', 'basis', 'basketball', 'baskets', 'basquiat', 'bass', 'batteries', 'battery', 'batterys', 'battle', 'bay', 'bayonce', 'bbc', 'bce', 'be', 'beach', 'beaches', 'beams', 'beat', 'beaten', 'beats', 'beautiful', 'became', 'because', 'beck', 'beckham', 'become', 'becomes', 'becoming', 'bed', 'been', 'beethoven', 'before', 'beforehand', 'beg', 'began', 'begin', 'beginning', 'begun', 'behalf', 'behavior', 'behaviors', 'behaviour', 'behind', 'beichaun', 'beichuan', 'beijing', 'being', 'beings', 'belief', 'beliefs', 'believable', 'believe', 'believed', 'believes', 'believing', 'bellucci', 'belong', 'belonged', 'belongs', 'beneficiaries', 'benefit', 'benefited', 'benjamin', 'berlin', 'besides', 'best', 'bestow', 'bestowed', 'bestsellers', 'better', 'between', 'bey', 'beyonce', 'beyoncé', 'beyond', 'bible', 'bic', 'bice', 'bicentenary', 'bicycle', 'big', 'biggest', 'bike', 'bikes', 'bill', 'billboard', 'billie', 'billion', 'billionaire', 'billionaires', 'bin', 'bind', 'biographer', 'biographies', 'biography', 'biogrpahers', 'biogrpahies', 'bird', 'birth', 'birthdate', 'birthday', 'birthplace', 'bisexual', 'black', 'blackface', 'blame', 'blamed', 'blankens', 'blasio', 'bless', 'blind', 'block', 'blockages', 'blocked', 'blofeld', 'blog', 'blow', 'blue', 'blurry', 'bo', 'boarders', 'boarding', 'boasted', 'boat', 'bob', 'bodhi', 'bodhisattva', 'bodhisattvas', 'bodhisattvayana', 'body', 'bodyguard', 'bomb', 'bombing', 'bond', 'bonus', 'boo', 'book', 'books', 'boot', 'bootylicious', 'border', 'borders', 'born', 'borough', 'boroughs', 'bossy', 'both', 'bothe', 'bottles', 'bought', 'boulevard', 'bound', 'boundaries', 'bowersox', 'bowie', 'bowl', 'bowstring', 'box', 'boxing', 'boycott', 'boys', 'brackish', 'brahmanic', 'brahmanism', 'brahminic', 'brahmins', 'brahms', 'brain', 'branch', 'branches', 'brand', 'branded', 'brands', 'brazil', 'breach', 'breached', 'break', 'breakthroughs', 'breakup', 'brick', 'bridge', 'bridges', 'brigade', 'bring', 'brion', 'britain', 'british', 'broad', 'broadcast', 'broadcaster', 'broadened', 'broadway', 'broadwood', 'broke', 'bronkhorst', 'bronkhurst', 'bronx', 'bronze', 'brooklyn', 'brother', 'brought', 'brownstone', 'bruell', 'bryan', 'buddha', 'buddhagohosa', 'buddhahood', 'buddhas', 'buddhism', 'buddhisma', 'buddhist', 'buddhists', 'buddism', 'buddists', 'budget', 'buget', 'build', 'builder', 'builders', 'building', 'buildings', 'built', 'bulbins', 'bulls', 'bundled', 'bundles', 'bunker', 'bureau', 'burial', 'buried', 'burma', 'burn', 'bus', 'buses', 'bush', 'busiest', 'business', 'but', 'button', 'buttons', 'buy', 'buyantu', 'buying', 'by', 'c', 'ca', 'cab', 'cable', 'cables', 'cabs', 'cadillac', 'caleb', 'california', 'call', 'called', 'calling', 'calls', 'calm', 'calvin', 'came', 'camille', 'campaign', 'can', 'canada', 'canal', 'canarsie', 'cancel', 'canceled', 'cancellation', 'cancelled', 'candice', 'candidate', 'candidates', 'cannons', 'canon', 'cantabile', 'capabilities', 'capable', 'capacity', 'cape', 'capital', 'capote', 'captivated', 'capture', 'captured', 'car', 'carbon', 'card', 'care', 'cared', 'career', 'carey', 'careys', 'cargo', 'caribbean', 'caring', 'carmen', 'carolina', 'carrie', 'carried', 'carry', 'carrying', 'cars', 'carter', 'carved', 'case', 'cash', 'cast', 'castro', 'casualties', 'catagorize', 'catalog', 'catalogue', 'catalyst', 'catastrophe', 'catch', 'categories', 'categorized', 'category', 'catered', 'catholic', 'caucasian', 'causal', 'causally', 'cause', 'caused', 'cctv', 'cd', 'cds', 'ce', 'cease', 'ceased', 'celebrate', 'celebration', 'celebrity', 'cell', 'celsius', 'cemetery', 'censored', 'censoring', 'census', 'center', 'centerpiece', 'centimeters', 'central', 'centre', 'cents', 'century', 'ceremonies', 'ceremony', 'certain', 'certificate', 'certifications', 'certified', 'cessation', 'chaillot', 'chain', 'chains', 'chair', 'challenge', 'challenged', 'challenger', 'championship', 'championships', 'chan', 'chance', 'chances', 'changchub', 'change', 'changed', 'changes', 'changing', 'channel', 'channels', 'character', 'characteristics', 'characterized', 'characterizes', 'characters', 'charge', 'charged', 'charges', 'charging', 'charitable', 'charity', 'charles', 'charlie', 'charlotte', 'chart', 'charter', 'chartered', 'charts', 'chase', 'chastis', 'chastised', 'checks', 'chemical', 'chen', 'chengdu', 'chest', 'chicago', 'chieco', 'chief', 'child', 'childhood', 'children', 'childress', 'chimamanda', 'chime', 'chimney', 'chin', 'china', 'chinatown', 'chinatowns', 'chinese', 'chipmunk', 'chocolate', 'choir', 'choose', 'chopin', 'chopiniana', 'chopins', 'chord', 'choreographed', 'choreographer', 'chose', 'chosen', 'choskunskyabs', 'chosrje', 'chris', 'christiaan', 'christian', 'christianity', 'christians', 'christina', 'christmas', 'christoph', 'chromatic', 'chronicle', 'chrysler', 'church', 'cinemascore', 'cinematographer', 'circling', 'circulate', 'circulated', 'circulation', 'cirrhosis', 'cite', 'cited', 'cites', 'cities', 'citing', 'citizen', 'citizenry', 'citizens', 'citizenship', 'city', 'citywide', 'civil', 'civilian', 'civilization', 'claesen', 'claim', 'claimed', 'claiming', 'claims', 'clairty', 'clark', 'clarkson', 'class', 'classic', 'classical', 'classification', 'classified', 'classroom', 'classrooms', 'clay', 'clean', 'clearly', 'clementi', 'clergy', 'cleric', 'click', 'client', 'climate', 'climb', 'clinics', 'clooney', 'close', 'closed', 'closely', 'closer', 'closest', 'clothes', 'clothing', 'cloud', 'clouds', 'club', 'co', 'coached', 'coast', 'cod', 'code', 'codes', 'coefficient', 'coin', 'coincided', 'coldest', 'colitis', 'collaborate', 'collaborated', 'collapse', 'collapsed', 'collapses', 'collect', 'collected', 'collecting', 'collection', 'collectors', 'college', 'collegiate', 'colonel', 'colonized', 'color', 'colorful', 'coloring', 'colors', 'columbia', 'colve', 'comapred', 'combat', 'combine', 'combined', 'come', 'comedian', 'comedy', 'comes', 'comfortable', 'comic', 'coming', 'commanded', 'commander', 'commands', 'commemorate', 'commemoration', 'commence', 'commended', 'comment', 'commentator', 'commented', 'commercial', 'commercially', 'commission', 'commissioned', 'commit', 'committed', 'common', 'commonly', 'communciations', 'communicate', 'communication', 'communications', 'communities', 'community', 'commutation', 'commuter', 'compalin', 'companies', 'companion', 'companions', 'company', 'comparable', 'comparative', 'comparatively', 'compare', 'compared', 'compares', 'comparison', 'comparisons', 'compatibility', 'compatible', 'compel', 'compensation', 'compete', 'competing', 'competition', 'competitor', 'compilation', 'compiled', 'complain', 'complaining', 'complaints', 'complete', 'completed', 'completely', 'completing', 'complex', 'complications', 'complimented', 'component', 'components', 'compose', 'composed', 'composer', 'composers', 'composing', 'composisition', 'composition', 'compositions', 'compositons', 'comprise', 'comprised', 'computer', 'computers', 'concealing', 'concentrated', 'concentrating', 'concentration', 'concept', 'concepts', 'conceptual', 'concern', 'concerned', 'concerning', 'concerns', 'concert', 'concerto', 'concertos', 'concerts', 'concluded', 'conclusion', 'condensed', 'condition', 'conditioned', 'conditions', 'conduct', 'conducted', 'confer', 'conference', 'confide', 'confident', 'confidential', 'confine', 'confirm', 'confirmed', 'conflict', 'conflicts', 'confucian', 'congress', 'connect', 'connected', 'connecter', 'connecticut', 'connecting', 'connection', 'connections', 'connectivity', 'connector', 'connects', 'conquer', 'conquest', 'consciousness', 'conscripted', 'consecutive', 'conservatoire', 'conservatory', 'consider', 'considered', 'considering', 'considers', 'consists', 'console', 'consoles', 'constant', 'constantine', 'constantly', 'constitute', 'constitution', 'constructed', 'construction', 'consulate', 'consultant', 'consumers', 'consumption', 'contact', 'contacts', 'contain', 'contained', 'contains', 'contemplate', 'contemplative', 'contemporaries', 'contemporary', 'content', 'contented', 'contents', 'contest', 'contestant', 'contestants', 'contingency', 'contingent', 'continuation', 'continue', 'continued', 'continuously', 'contract', 'contrary', 'contribute', 'contributed', 'contributing', 'contribution', 'contributions', 'contrived', 'control', 'controlled', 'controller', 'controls', 'controversial', 'controversy', 'convert', 'converted', 'converts', 'convicted', 'convinced', 'convoys', 'cook', 'cooker', 'cookers', 'cooking', 'cool', 'coolidge', 'cooling', 'copies', 'copper', 'copy', 'copying', 'copyist', 'copyright', 'copywriter', 'core', 'corey', 'cornell', 'corners', 'coronation', 'coroner', 'corp', 'corporation', 'correct', 'correlates', 'correlation', 'correspondent', 'corresponds', 'cosmetology', 'cosmos', 'cost', 'costliest', 'costs', 'cotton', 'could', 'council', 'councilors', 'councilperson', 'counted', 'countering', 'countries', 'country', 'counts', 'county', 'couple', 'course', 'court', 'courthouse', 'courtroom', 'courts', 'cousin', 'cover', 'coverage', 'covered', 'cowell', 'cracks', 'crafting', 'craig', 'crash', 'crashed', 'craving', 'crazy', 'create', 'created', 'creates', 'creating', 'creation', 'creative', 'creativeness', 'creator', 'creature', 'credit', 'credited', 'credits', 'creek', 'crew', 'cries', 'crime', 'crisis', 'critic', 'critical', 'critically', 'criticism', 'criticisms', 'criticize', 'criticized', 'critics', 'crop', 'cross', 'crossed', 'crossover', 'croton', 'crowdfunding', 'crowds', 'crown', 'cruel', 'crush', 'crushed', 'crystal', 'crystalline', 'csp', 'cst', 'cuba', 'cubic', 'cudi', 'cultivates', 'cultivating', 'cultivation', 'cultivator', 'cultural', 'culture', 'curiosity', 'current', 'currently', 'customized', 'cut', 'cutoff', 'cuts', 'cutting', 'cycle', 'cycles', 'cyclic', 'cyclone', 'cyclones', 'cyprus', 'da', 'dabble', 'dagoult', 'daily', 'dalai', 'dalit', 'dam', 'damage', 'damaged', 'dams', 'dana', 'dance', 'dancers', 'danger', 'dangerous', 'dangerously', 'daniel', 'danjaq', 'dark', 'darker', 'darnells', 'data', 'date', 'dates', 'dating', 'daughter', 'daughtry', 'dave', 'david', 'day', 'daylights', 'days', 'db10', 'db10s', 'dbus', 'dc', 'de', 'dead', 'deadliest', 'deal', 'dealing', 'deals', 'dealt', 'death', 'deaths', 'debris', 'debussy', 'debut', 'debuted', 'decade', 'decades', 'deceased', 'december', 'decide', 'decided', 'deciduous', 'decision', 'declare', 'declared', 'decline', 'declined', 'declining', 'decorates', 'decrease', 'decreased', 'dedicate', 'dedicated', 'deeds', 'deem', 'deemed', 'deep', 'deeply', 'def', 'defeat', 'defeated', 'defend', 'defended', 'defending', 'deficiency', 'defilements', 'defined', 'definition', 'degarmo', 'degeneres', 'degree', 'degrees', 'deity', 'deja', 'delacroix', 'delaware', 'delayed', 'delegation', 'delicate', 'deliver', 'delivered', 'delivering', 'delusion', 'demand', 'demo', 'democratic', 'democrats', 'demolished', 'demonizing', 'demonstrate', 'demoralizing', 'denied', 'denies', 'density', 'deny', 'depart', 'department', 'departure', 'dependent', 'depict', 'depiction', 'deployed', 'depressed', 'depression', 'depth', 'derail', 'dereon', 'derided', 'derive', 'derogatory', 'deréon', 'des', 'desagreements', 'descendant', 'descendants', 'descendent', 'describe', 'described', 'describes', 'describing', 'description', 'descriptive', 'desert', 'deshin', 'design', 'designated', 'designed', 'designer', 'desire', 'desired', 'desktop', 'despite', 'desroches', 'destiny', 'destroy', 'destroyed', 'detailed', 'details', 'detect', 'deteriorate', 'deteriorating', 'determine', 'determined', 'determines', 'detlef', 'detonate', 'develop', 'developed', 'developing', 'development', 'device', 'devices', 'devils', 'devoted', 'devotion', 'devotional', 'dewyze', 'dharma', 'dharmagupta', 'dharmas', 'dhyana', 'di', 'diabetes', 'diaghilev', 'diagnosis', 'dialect', 'dialogue', 'diamonds', 'diana', 'diane', 'dictionary', 'did', 'die', 'died', 'diesel', 'differ', 'difference', 'different', 'difficult', 'difficulties', 'digest', 'digital', 'digitally', 'dignitaries', 'dill', 'dining', 'dioxide', 'dipavamsa', 'diplomacy', 'diplomatic', 'direct', 'directed', 'direction', 'directions', 'directly', 'director', 'disabled', 'disagree', 'disagreement', 'disappeared', 'disaster', 'disasters', 'disban', 'discerned', 'discharge', 'discharges', 'disciplinary', 'disclaim', 'discography', 'discontinued', 'discourage', 'discourse', 'discourses', 'discover', 'discovered', 'discovery', 'discrepancy', 'discussed', 'discusses', 'discussion', 'disease', 'dishes', 'disinfect', 'disinfection', 'disk', 'dismiss', 'dispatched', 'displaced', 'displacement', 'display', 'displayed', 'displaying', 'dispute', 'disqualified', 'disque', 'disregard', 'disregarded', 'disruption', 'distance', 'distillation', 'distinctive', 'distorted', 'distortion', 'distributed', 'district', 'districts', 'disturbed', 'ditmas', 'diva', 'diverted', 'divide', 'divided', 'dividing', 'divine', 'division', 'dj', 'dna', 'do', 'dock', 'doctor', 'doctorate', 'doctors', 'doctrinal', 'doctrine', 'document', 'documentary', 'documented', 'dodgers', 'doe', 'does', 'dog', 'doing', 'dolby', 'dollar', 'dollars', 'domestic', 'dominant', 'dominate', 'don', 'donate', 'donated', 'donation', 'donations', 'donda', 'done', 'donna', 'donor', 'dorje', 'doubling', 'douglaston', 'down', 'downloads', 'downstream', 'dows', 'dr', 'draft', 'drafts', 'drama', 'draw', 'drawing', 'draws', 'dream', 'dreamgirls', 'dress', 'dresse', 'dressed', 'drew', 'drink', 'drinkable', 'drinking', 'drive', 'drivers', 'drives', 'drm', 'drop', 'dropout', 'dropped', 'dropping', 'drought', 'drove', 'drug', 'dry', 'du', 'dubose', 'duchy', 'due', 'duet', 'duets', 'dujiangyan', 'duke', 'dukkha', 'dungeon', 'dungeons', 'duo', 'duration', 'during', 'dutch', 'dwindled', 'dying', 'dynasties', 'dynasty', 'düsseldorf', 'e', 'e3', 'each', 'eagles', 'earlier', 'earliest', 'early', 'earn', 'earned', 'earning', 'earnings', 'earphone', 'earth', 'earthquake', 'earthquakes', 'ease', 'easily', 'east', 'eastern', 'eastward', 'eat', 'economic', 'economically', 'economics', 'economy', 'ed', 'edge', 'edict', 'edicts', 'edit', 'edited', 'edition', 'editions', 'editor', 'education', 'edwin', 'effect', 'effective', 'effectively', 'effects', 'effort', 'efforts', 'ego', 'eight', 'eightfold', 'eighth', 'elaborate', 'eldest', 'election', 'electricity', 'electrolysis', 'electronic', 'element', 'elementary', 'elements', 'elevated', 'elevations', 'eleven', 'eleventh', 'elf', 'eliminate', 'eliminated', 'elimination', 'eliminations', 'ellen', 'ellis', 'else', 'em', 'embargo', 'embark', 'embassy', 'embellishments', 'embodies', 'embroidery', 'emerge', 'emerged', 'emergency', 'emigrate', 'emilia', 'emissaries', 'emmett', 'emotions', 'emperor', 'emperors', 'emphasis', 'empire', 'employed', 'employee', 'employees', 'employment', 'employs', 'emplyees', 'emporio', 'empowered', 'empowerment', 'emptiness', 'empty', 'emts', 'enable', 'enabled', 'enabling', 'ename', 'encountered', 'encounters', 'encourage', 'encouraged', 'encourages', 'encyclopedia', 'end', 'endeavors', 'ended', 'ending', 'endorse', 'endorsement', 'endure', 'enemies', 'enemy', 'energies', 'energy', 'engaged', 'engagement', 'engine', 'engineer', 'engineering', 'engineers', 'engines', 'england', 'english', 'enjoy', 'enjoyed', 'enlightened', 'enlightenment', 'enlist', 'ensemble', 'ensure', 'entail', 'enter', 'entered', 'enterprise', 'enterprises', 'enters', 'entertainer', 'entertainers', 'entertaining', 'entertainment', 'enthrone', 'entire', 'entirely', 'entity', 'entry', 'environment', 'environmental', 'envoys', 'eon', 'epic', 'epicenter', 'episode', 'episodes', 'eponymous', 'eq', 'equal', 'equated', 'equator', 'equipment', 'equipped', 'era', 'eradicated', 'eradicates', 'erard', 'eras', 'erased', 'eric', 'ericsson', 'erie', 'error', 'eruption', 'escape', 'escaped', 'escapes', 'esoteric', 'essay', 'essential', 'establish', 'established', 'establishment', 'establishments', 'estate', 'esteem', 'estevao', 'estimate', 'estimated', 'estimations', 'estrella', 'estuary', 'estêvão', 'eternal', 'ethics', 'ethnic', 'ethnically', 'ethnicity', 'etiquette', 'etta', 'eu', 'eunuch', 'euorpeans', 'europe', 'european', 'evacuate', 'evacuated', 'evacuation', 'evan', 'eve', 'evelyn', 'even', 'evening', 'event', 'events', 'eventually', 'ever', 'every', 'everyone', 'everything', 'evidence', 'ewell', 'ex', 'exactly', 'exajoules', 'example', 'examples', 'exceed', 'exceeded', 'except', 'excess', 'exchange', 'exchanges', 'excluded', 'exclusively', 'executive', 'executives', 'executor', 'exercise', 'exhibit', 'exile', 'exising', 'exist', 'existance', 'existed', 'existence', 'existent', 'exotic', 'expand', 'expatriates', 'expected', 'expedition', 'expensive', 'experience', 'experiencing', 'explain', 'explained', 'explanations', 'exploit', 'exploited', 'explore', 'explored', 'explorer', 'explores', 'exploring', 'export', 'exposed', 'exposition', 'expositions', 'exposure', 'express', 'expressed', 'expressionism', 'expressway', 'extant', 'extension', 'extensive', 'extensively', 'extinction', 'extinguish', 'extraction', 'extremes', 'eyes', 'f', 'face', 'facility', 'facing', 'factions', 'factor', 'factors', 'factory', 'fahrenheit', 'fail', 'failed', 'fairplay', 'faith', 'faked', 'fall', 'falls', 'falsely', 'fame', 'familial', 'familiarity', 'families', 'family', 'famous', 'famously', 'fan', 'fans', 'fantasia', 'fantasy', 'far', 'farmers', 'fascinated', 'fascination', 'fashion', 'fashions', 'faster', 'fatburger', 'father', 'fathers', 'fault', 'faults', 'favor', 'favored', 'favorite', 'favors', 'fc', 'fdny', 'fear', 'feature', 'featured', 'features', 'featuring', 'february', 'federal', 'fee', 'feeds', 'feel', 'feelings', 'feels', 'fees', 'feet', 'felix', 'fell', 'fella', 'fellow', 'felt', 'female', 'females', 'feminism', 'feminist', 'ferry', 'festival', 'feud', 'few', 'fewer', 'fi', 'fiance', 'fiancee', 'fiancé', 'fiber', 'fictionalized', 'field', 'fiennes', 'fierce', 'fifteenth', 'fifth', 'fifths', 'fig', 'fight', 'fighting', 'figure', 'figures', 'file', 'filed', 'files', 'filing', 'filled', 'film', 'filmakers', 'filmed', 'filming', 'films', 'filtering', 'final', 'finale', 'finalist', 'finalists', 'finally', 'finals', 'financial', 'financially', 'finch', 'find', 'finding', 'findings', 'finds', 'fine', 'fingering', 'finish', 'finished', 'fire', 'fired', 'firefighters', 'fires', 'firewire', 'firm', 'first', 'fist', 'fit', 'five', 'fix', 'fixed', 'flawless', 'fleeing', 'fleet', 'fleming', 'flew', 'flight', 'flights', 'flooding', 'floor', 'flourishing', 'flowers', 'flown', 'flows', 'flux', 'fly', 'fo', 'focal', 'focus', 'focused', 'focuses', 'folder', 'folk', 'follow', 'followed', 'followers', 'following', 'follows', 'font', 'fontana', 'food', 'foot', 'football', 'for', 'forays', 'force', 'forced', 'forces', 'ford', 'forego', 'foreign', 'foreseen', 'forever', 'forget', 'forgiveness', 'form', 'formal', 'formally', 'format', 'formation', 'formats', 'formatted', 'formed', 'former', 'formerly', 'formless', 'forms', 'formula', 'fort', 'forth', 'fortune', 'forward', 'fossil', 'fought', 'found', 'foundation', 'founded', 'founder', 'founding', 'four', 'fourteen', 'fourteenth', 'fourth', 'fox', 'foxconn', 'fraction', 'fracture', 'fradianis', 'fragility', 'fragrance', 'frame', 'france', 'franchise', 'franchomme', 'francis', 'francisco', 'frank', 'franklin', 'franz', 'free', 'freed', 'freedom', 'french', 'frequently', 'fresh', 'freshmen', 'freshwater', 'friederike', 'friedrich', 'friend', 'friends', 'friendship', 'from', 'front', 'frontier', 'fruit', 'fryderyk', 'frédéric', 'fuel', 'fuels', 'full', 'fuller', 'fully', 'function', 'functionality', 'functions', 'fund', 'fundamental', 'funding', 'funds', 'funeral', 'furnishings', 'furs', 'further', 'futile', 'future', 'gaddafi', 'gaga', 'gain', 'gained', 'gakkai', 'galleries', 'game', 'gamecube', 'gameplay', 'games', 'gamespy', 'gamestop', 'gang', 'gangs', 'ganondorf', 'gao', 'garden', 'garment', 'garments', 'garnered', 'garrison', 'garuda', 'gary', 'gases', 'gateway', 'gather', 'gathered', 'gathering', 'gautama', 'gave', 'gay', 'gelug', 'gen', 'gender', 'general', 'generally', 'generate', 'generated', 'generation', 'geng', 'genghis', 'genre', 'genres', 'genshin', 'geographical', 'geographicla', 'geography', 'geological', 'geologists', 'geophysics', 'george', 'georgia', 'german', 'germany', 'gerstmann', 'gestures', 'get', 'gets', 'getters', 'getting', 'ghost', 'giants', 'gibson', 'gift', 'gifted', 'gifts', 'gigawatts', 'gini', 'giovani', 'giovanni', 'giraud', 'girl', 'girlfriend', 'girls', 'give', 'given', 'gives', 'giving', 'glacier', 'gladkowska', 'glass', 'glastonbury', 'glauber', 'glazed', 'glickman', 'global', 'globe', 'glories', 'glory', 'glover', 'gloves', 'glowing', 'glue', 'go', 'goal', 'god', 'goddard', 'godfather', 'godiva', 'going', 'gold', 'golddigger', 'golden', 'goldmember', 'golf', 'golos', 'gomes', 'gone', 'good', 'gooding', 'goods', 'google', 'goring', 'got', 'gotamas', 'governed', 'governing', 'government', 'governor', 'governs', 'gq', 'grab', 'gradual', 'gradually', 'graduate', 'graduated', 'graduation', 'grammies', 'grammy', 'grammys', 'grand', 'grandiose', 'grandma', 'grandson', 'grant', 'granted', 'graphics', 'graveside', 'gray', 'great', 'greater', 'greatest', 'greatly', 'greed', 'greek', 'greeks', 'green', 'greenhouse', 'greenhouses', 'greenwood', 'greet', 'gregory', 'grid', 'gross', 'grossed', 'grossing', 'ground', 'grounds', 'group', 'grouped', 'groups', 'grow', 'growing', 'grows', 'growth', 'grzymała', 'gtsang', 'guang', 'guanxian', 'guardian', 'guards', 'guarini', 'guatama', 'gucci', 'guest', 'guests', 'guggenheim', 'guhyasamaja', 'guideline', 'guidelines', 'guiding', 'guinness', 'guitar', 'gun', 'gunplay', 'guy', 'gwyneth', 'gyaincain', 'gyaltsen', 'gyatso', 'güshi', 'hack', 'hackers', 'had', 'hair', 'hairstyles', 'haiti', 'half', 'hall', 'hallelujah', 'halloween', 'hallé', 'halt', 'ham', 'hamilton', 'han', 'hand', 'handles', 'handling', 'hands', 'hannes', 'hanshin', 'hanwang', 'hanz', 'happen', 'happened', 'happening', 'happens', 'happily', 'harbor', 'hard', 'hardest', 'hardly', 'hardware', 'harmful', 'harmonic', 'harness', 'harnessed', 'harper', 'harrison', 'hart', 'has', 'hassling', 'hate', 'hatred', 'have', 'having', 'hazard', 'hd', 'he', 'head', 'headline', 'headlined', 'headliner', 'headphone', 'headphones', 'headquartered', 'headquarters', 'heal', 'health', 'healthcare', 'hear', 'hearbreak', 'heard', 'hearers', 'hearing', 'heart', 'heartbreak', 'heartbreaks', 'heat', 'heater', 'heaters', 'heating', 'heavens', 'heavily', 'heavy', 'hectares', 'height', 'heir', 'held', 'helicopter', 'helicopters', 'help', 'helped', 'helpers', 'helpful', 'helps', 'henri', 'henry', 'her', 'here', 'heritage', 'herself', 'herz', 'hey', 'hhc', 'hi', 'hiatus', 'hick', 'hicks', 'hidden', 'hide', 'hierarchs', 'high', 'higher', 'highest', 'highly', 'highschools', 'highway', 'highways', 'hil', 'hildebrand', 'hill', 'hiller', 'him', 'himalayan', 'himself', 'hinayana', 'hinderance', 'hindrance', 'hinduism', 'hinx', 'hip', 'hiphop', 'hire', 'hired', 'his', 'hisashi', 'hispanic', 'historian', 'historians', 'historical', 'history', 'hit', 'hits', 'hive', 'hockey', 'hoe', 'hoffler', 'hok', 'hold', 'holder', 'holding', 'holds', 'holiday', 'holland', 'hollywood', 'holy', 'home', 'homeland', 'homeless', 'homes', 'homesick', 'hometown', 'homicides', 'homosexual', 'hong', 'hongwu', 'honor', 'honorary', 'honory', 'hop', 'hope', 'horace', 'horizontal', 'horse', 'horseback', 'horses', 'horticulture', 'hospital', 'hospitalized', 'hospitals', 'host', 'hosted', 'hostile', 'hosts', 'hot', 'hotel', 'hottest', 'hou', 'hour', 'hours', 'house', 'housed', 'household', 'households', 'houses', 'housing', 'houston', 'how', 'hoyte', 'hoytema', 'hp', 'hteir', 'hudson', 'huge', 'hula', 'human', 'humanitarian', 'humans', 'humid', 'humidity', 'humiliate', 'humor', 'hunter', 'hurricane', 'husband', 'hutchings', 'hvac', 'hybrid', 'hydroelectricity', 'hylian', 'hymn', 'hyrule', 'i', 'ian', 'ice', 'id', 'idea', 'ideal', 'ideas', 'identified', 'identifies', 'identify', 'identity', 'ideology', 'idol', 'idols', 'if', 'ign', 'ignjatovic', 'ignorance', 'ignore', 'ignored', 'ii', 'ill', 'illegal', 'illiteracy', 'illness', 'illnesses', 'illusion', 'illustrated', 'image', 'images', 'imagine', 'imagined', 'imax', 'immeasurable', 'immeasurables', 'immediately', 'immigrants', 'immigration', 'immortalized', 'impact', 'impacted', 'impactful', 'imperatives', 'imperial', 'impermanence', 'implement', 'implementation', 'implemented', 'implementing', 'important', 'importing', 'imposed', 'impressions', 'impromptu', 'improve', 'improved', 'improvement', 'improvisation', 'impulse', 'in', 'inability', 'inaugural', 'inauguration', 'inc', 'incentive', 'incentives', 'inches', 'incident', 'include', 'included', 'includes', 'including', 'inclusion', 'income', 'incoming', 'inconveniently', 'incorporates', 'increase', 'increased', 'increases', 'increasing', 'independent', 'index', 'india', 'indian', 'indicates', 'indie', 'indirectly', 'individual', 'individuals', 'indonesian', 'induction', 'indulgence', 'industrial', 'industry', 'inerconnected', 'infatuated', 'infirmaries', 'influence', 'influenced', 'influences', 'influential', 'inforcement', 'information', 'infrigement', 'inherit', 'initial', 'initially', 'initiate', 'initiated', 'initiation', 'injure', 'injured', 'injury', 'inland', 'inn', 'innate', 'innocent', 'innumerable', 'input', 'inputs', 'inquiry', 'inseparability', 'insight', 'insist', 'insisted', 'insolation', 'inspect', 'inspected', 'inspection', 'inspects', 'inspiration', 'inspirations', 'inspire', 'inspired', 'inspires', 'inspiring', 'instability', 'install', 'instances', 'instated', 'instead', 'institute', 'institution', 'institutions', 'instructed', 'instruction', 'instructions', 'instructor', 'instrument', 'instrumental', 'instruments', 'insult', 'insulted', 'insurgents', 'insurrection', 'intact', 'integral', 'integration', 'integrity', 'intellectual', 'intelligence', 'intend', 'intended', 'intensified', 'intensity', 'intentional', 'intentions', 'interact', 'interaction', 'interbank', 'interconnected', 'interdependent', 'interest', 'interested', 'interface', 'interfaced', 'interfacing', 'intermediate', 'international', 'internationally', 'internet', 'interpreted', 'interpublic', 'interrupt', 'interview', 'interviews', 'intimate', 'into', 'introduce', 'introduced', 'introducing', 'introduction', 'invaded', 'invasion', 'invent', 'invented', 'inventor', 'invest', 'investigated', 'investigating', 'investigation', 'investment', 'invitation', 'invitations', 'invite', 'invited', 'invocation', 'involve', 'involved', 'involves', 'involving', 'ios', 'ipad', 'ipg', 'iphone', 'ipod', 'ipods', 'irene', 'irish', 'irreplaceable', 'irreversable', 'is', 'island', 'islands', 'iso', 'israel', 'issue', 'issues', 'issuing', 'it', 'italian', 'item', 'items', 'iterations', 'itinerant', 'itrip', 'its', 'itself', 'itunes', 'ivy', 'j', 'jack', 'jackass', 'jackie', 'jackson', 'jam', 'jamaica', 'james', 'jams', 'jane', 'january', 'japan', 'japanese', 'jason', 'jataka', 'javier', 'jax', 'jay', 'jazz', 'je', 'jean', 'jeff', 'jem', 'jena', 'jennifer', 'jenny', 'jersey', 'jerusalem', 'jesse', 'jessica', 'jesus', 'jets', 'jewels', 'jewish', 'jews', 'jfk', 'jhana', 'jhanas', 'jiabao', 'jiajing', 'jianwen', 'jiawei', 'jimmy', 'jin', 'job', 'jobs', 'jock', 'jody', 'john', 'johnny', 'johnson', 'join', 'joined', 'joining', 'joint', 'jon', 'jones', 'jop', 'jordin', 'josef', 'josephine', 'journal', 'journalism', 'journalist', 'journey', 'jpeg', 'jr', 'juan', 'judge', 'judges', 'judgmental', 'jukebox', 'julian', 'july', 'jump', 'june', 'junior', 'jurisdiction', 'jurors', 'jury', 'just', 'justice', 'justin', 'juyuan', 'kaddafi', 'kane', 'kangxi', 'kansas', 'kanye', 'kardashian', 'karen', 'karma', 'karmapa', 'kashmir', 'katherine', 'katrina', 'katy', 'kazakhstan', 'keep', 'keeps', 'keith', 'kellie', 'kelly', 'kenneth', 'kentucky', 'kept', 'kermode', 'key', 'keyboards', 'khan', 'khatun', 'khubilai', 'kicked', 'kid', 'kidnapped', 'kidnaps', 'kidney', 'kill', 'killed', 'killing', 'kilometer', 'kilometers', 'kim', 'kimmel', 'kind', 'kinds', 'king', 'kingdom', 'kingdoms', 'klieger', 'klinik', 'km', 'kmh', 'knee', 'knew', 'knievel', 'know', 'knowledge', 'known', 'koan', 'kobylańska', 'kolmaš', 'komoto', 'kondo', 'korea', 'kramer', 'krasiński', 'kree', 'kris', 'krishnan', 'krsna', 'kublai', 'kwhm2', 'köppen', 'la', 'label', 'labeled', 'labor', 'labored', 'lack', 'lacking', 'laden', 'lades', 'ladies', 'ladieu', 'lady', 'laguardia', 'laird', 'lake', 'lakes', 'lam', 'lama', 'lamas', 'lamb', 'lamber', 'lamericain', 'lampooned', 'land', 'landing', 'landmark', 'landmarks', 'landscape', 'landscaped', 'landslide', 'language', 'languages', 'lanka', 'lapse', 'laptop', 'large', 'larger', 'largest', 'larghetto', 'larter', 'las', 'last', 'latavia', 'late', 'later', 'latest', 'latin', 'latitudes', 'latoya', 'latter', 'latvia', 'lauded', 'launch', 'launched', 'lauren', 'law', 'lawrence', 'laws', 'lawsuit', 'lawsuits', 'lawyer', 'lax', 'lay', 'laypersons', 'lays', 'laywer', 'lead', 'leader', 'leaders', 'leadership', 'leading', 'leads', 'leafless', 'league', 'leagues', 'leak', 'leaked', 'leaks', 'leap', 'learn', 'learned', 'learning', 'learnt', 'least', 'leave', 'leaving', 'led', 'lee', 'left', 'leg', 'legacy', 'legal', 'legalize', 'legalized', 'legato', 'legend', 'legislation', 'legitimacy', 'legitimizing', 'lenape', 'length', 'leon', 'less', 'lessard', 'lessons', 'let', 'letter', 'letters', 'level', 'levels', 'leverage', 'lgb', 'lgbt', 'lhasa', 'liao', 'liar', 'liberalism', 'liberate', 'liberated', 'liberating', 'liberation', 'liberty', 'librarians', 'library', 'libyan', 'licence', 'license', 'lie', 'life', 'lifetimes', 'light', 'lightened', 'lightening', 'lightning', 'like', 'likely', 'likeness', 'likes', 'limit', 'limited', 'limitless', 'lincoln', 'lind', 'line', 'lines', 'linggu', 'link', 'linked', 'lionel', 'liquid', 'list', 'listed', 'listen', 'listeners', 'listening', 'liszt', 'liszy', 'lit', 'literary', 'literature', 'liters', 'litres', 'little', 'liu', 'live', 'lived', 'lives', 'livestock', 'living', 'llc', 'loan', 'local', 'locals', 'located', 'location', 'locations', 'lockdown', 'lofficiel', 'logic', 'logo', 'lok', 'london', 'lonelier', 'long', 'longer', 'longest', 'longmen', 'longmenshan', 'longtime', 'look', 'looked', 'looking', 'lopez', 'loreal', 'los', 'lose', 'losing', 'loss', 'losses', 'lost', 'lot', 'lots', 'lotus', 'loud', 'love', 'lovers', 'loving', 'low', 'lower', 'lowest', 'ltd', 'luciano', 'luckett', 'lucky', 'ludwika', 'lund', 'lyceum', 'lying', 'lyric', 'lyrical', 'lyrics', 'lythgoe', 'lì', 'm', 'mac', 'macau', 'machine', 'machinery', 'macintouch', 'macy', 'madd', 'made', 'madeleine', 'madhyamaka', 'madison', 'madonna', 'mafia', 'magadha', 'magazine', 'magazines', 'magnitude', 'mahasanghika', 'mahasanghikas', 'mahayana', 'mahayanists', 'mahayava', 'mahayna', 'mahjong', 'maid', 'maiden', 'mail', 'main', 'mainly', 'mainstream', 'maintain', 'maintains', 'major', 'majorca', 'majority', 'make', 'maker', 'makers', 'makes', 'makeup', 'making', 'malakar', 'male', 'males', 'mama', 'mamas', 'man', 'manage', 'managed', 'management', 'manager', 'manages', 'manchu', 'mandala', 'manga', 'manhattan', 'manhatten', 'manifestation', 'manned', 'manner', 'mantras', 'manual', 'manually', 'manufactured', 'manufacturers', 'manufactures', 'manufacturing', 'manumission', 'many', 'mao', 'map', 'marathon', 'march', 'marco', 'marcus', 'maria', 'mariah', 'marie', 'mario', 'mark', 'marked', 'market', 'marketed', 'markets', 'marks', 'marquis', 'marriage', 'marriages', 'married', 'marry', 'marrying', 'marshal', 'martin', 'mask', 'mass', 'massing', 'massive', 'master', 'mastering', 'matching', 'material', 'materials', 'math', 'matt', 'matter', 'matthew', 'maturing', 'maturity', 'maudie', 'maurice', 'mauryan', 'maximalist', 'maximum', 'may', 'mayjor', 'mayor', 'mazurkas', 'mc', 'mcclory', 'mccreery', 'mcphee', 'mcwhorter', 'me', 'mean', 'meaning', 'means', 'meant', 'measure', 'mechanic', 'mechanical', 'medal', 'media', 'medical', 'medicine', 'medics', 'medina', 'meditation', 'meditative', 'meet', 'meeting', 'meetings', 'mekhi', 'melodies', 'melodramatic', 'melody', 'melting', 'member', 'members', 'membership', 'memorial', 'memory', 'men', 'menagerie', 'mendelssohn', 'mendes', 'mental', 'mentioned', 'mentions', 'mentor', 'mentored', 'mentors', 'menu', 'merged', 'meritorious', 'merkel', 'message', 'met', 'metacritic', 'metacritics', 'metal', 'metaphysical', 'metaphysics', 'meter', 'meters', 'method', 'methods', 'metlife', 'metro', 'metropolitan', 'mexican', 'mexico', 'meyers', 'mhayana', 'mi6', 'mianyang', 'mic', 'michael', 'michel', 'michelin', 'mickiewicz', 'microsoft', 'mid', 'middle', 'midna', 'midtown', 'might', 'mike', 'mile', 'miles', 'milieu', 'military', 'militia', 'millimeters', 'million', 'millionaires', 'millions', 'minaj', 'mind', 'mindful', 'mindfulness', 'minds', 'ming', 'mini', 'minimum', 'minister', 'ministry', 'minor', 'minster', 'minuit', 'minute', 'minutes', 'mirror', 'miscarriage', 'misconduct', 'miss', 'missing', 'mission', 'mistress', 'mitigate', 'mixtape', 'mob', 'mobile', 'mocked', 'mockingbird', 'model', 'modeled', 'modelling', 'models', 'moderate', 'moderation', 'modern', 'moha', 'molesting', 'mom', 'moment', 'monarch', 'monastic', 'monastics', 'money', 'moneypenny', 'mongol', 'mongolia', 'mongolian', 'mongols', 'monica', 'monitor', 'monk', 'monks', 'monographic', 'monroeville', 'montgomery', 'month', 'months', 'monument', 'mood', 'moral', 'more', 'morocco', 'morph', 'mortification', 'most', 'mostly', 'mother', 'motivated', 'motivation', 'motto', 'mount', 'mountain', 'mountains', 'mourn', 'mourning', 'move', 'moved', 'movement', 'movements', 'movie', 'movies', 'moving', 'mozart', 'mp3', 'mr', 'mrs', 'ms', 'mtv', 'mu', 'muammar', 'much', 'mukden', 'multiple', 'municipal', 'murder', 'murders', 'murdoch', 'muse', 'museum', 'music', 'musical', 'musicality', 'musicals', 'musician', 'musicians', 'musicologist', 'must', 'mutual', 'mutually', 'my', 'myanmar', 'myers', 'myriarchies', 'mysterious', 'myth', 'müller', 'n', 'nagarjuna', 'name', 'named', 'names', 'namgyal', 'nanjing', 'nano', 'nanos', 'nargis', 'narrative', 'nasdaq', 'nation', 'national', 'nationalism', 'nationalities', 'nationality', 'nations', 'native', 'natively', 'natives', 'natural', 'nature', 'nba', 'nbc', 'neal', 'near', 'neck', 'need', 'neede', 'needed', 'needing', 'needs', 'negative', 'negatively', 'neighbor', 'neighborhood', 'neighborhoods', 'neighboring', 'neither', 'neo', 'net', 'netherland', 'netherlands', 'nets', 'network', 'networks', 'never', 'new', 'newark', 'newer', 'newest', 'newman', 'news', 'newspaper', 'newspapers', 'newtown', 'next', 'nfl', 'ngozi', 'nhl', 'nibbana', 'niccolo', 'niccolò', 'nick', 'nicki', 'nickname', 'nicknamed', 'nicky', 'nicolas', 'nidana', 'nidāna', 'nidānakathā', 'nidānas', 'nigel', 'nigerian', 'night', 'nights', 'nikaya', 'nine', 'nintendo', 'ninth', 'nirvana', 'no', 'nobel', 'noble', 'nocturne', 'nocturnes', 'nohant', 'nokia', 'nominal', 'nominated', 'nomination', 'nominations', 'non', 'norbu', 'north', 'northeast', 'northeastern', 'northern', 'nose', 'not', 'notable', 'notation', 'note', 'notebook', 'noted', 'notes', 'nothing', 'notice', 'noting', 'nourrit', 'novel', 'november', 'now', 'numan', 'number', 'numbered', 'numbers', 'numerous', 'nuns', 'nursing', 'ny', 'nyc', 'nyima', 'nypd', 'o2', 'obama', 'obamas', 'oberhauser', 'object', 'observations', 'observe', 'observer', 'obsessed', 'obstacles', 'obtain', 'obtainable', 'obtained', 'obtaining', 'ocarina', 'occasionally', 'occupation', 'occupied', 'occupy', 'occur', 'occured', 'occurred', 'occurring', 'occurs', 'ocean', 'oceans', 'octaves', 'october', 'of', 'ofen', 'off', 'offense', 'offer', 'offered', 'offering', 'offerings', 'offers', 'office', 'officer', 'officers', 'offices', 'official', 'officially', 'officials', 'often', 'oil', 'old', 'older', 'oldest', 'olympic', 'omitted', 'omnipresent', 'omniscience', 'on', 'once', 'one', 'ones', 'oneself', 'online', 'only', 'onstage', 'op', 'open', 'opened', 'opening', 'opera', 'operas', 'operate', 'operated', 'operates', 'operatic', 'operating', 'operation', 'operations', 'opinion', 'opp', 'opportunities', 'opportunity', 'oprah', 'optic', 'optimistic', 'opus', 'or', 'orange', 'orchestra', 'orchestral', 'orchestrated', 'orchestrations', 'order', 'ordered', 'ordering', 'ordon', 'ordos', 'organ', 'organic', 'organism', 'organist', 'organization', 'organizations', 'organize', 'organizes', 'oriented', 'origin', 'original', 'originally', 'originate', 'originated', 'origination', 'origins', 'os', 'osama', 'oscar', 'oshow', 'other', 'others', 'our', 'out', 'outburst', 'outdoor', 'outlawed', 'outline', 'outlines', 'output', 'outside', 'over', 'overabundance', 'overall', 'overcome', 'overhaul', 'overheating', 'overrated', 'oversee', 'overseeing', 'overseer', 'overtake', 'overthrow', 'overthrown', 'overworking', 'own', 'owned', 'owner', 'owners', 'ownership', 'owns', 'oxford', 'oxide', 'p', 'pablo', 'pabst', 'pacific', 'pack', 'package', 'pact', 'paganini', 'pages', 'paid', 'pain', 'pains', 'painted', 'pairs', 'palace', 'palette', 'pali', 'paltrow', 'pan', 'panda', 'pandas', 'panel', 'panels', 'panther', 'paparazzi', 'paper', 'paperback', 'parabolic', 'parachuted', 'parade', 'paradox', 'paraffin', 'parallels', 'paramedics', 'paramitas', 'pareles', 'parent', 'parents', 'parinirvana', 'paris', 'parish', 'parisian', 'park', 'parker', 'parks', 'parkscore', 'parkwood', 'parodies', 'parsons', 'part', 'partcipate', 'partial', 'partially', 'participate', 'participated', 'particpate', 'parties', 'partitioned', 'partner', 'partnered', 'partnership', 'parts', 'party', 'pass', 'passages', 'passed', 'passengers', 'passion', 'passive', 'passport', 'past', 'pastelle', 'pat', 'patched', 'patent', 'patented', 'path', 'patients', 'patimokkha', 'patriotic', 'patronage', 'paula', 'pauline', 'pay', 'paying', 'pazz', 'pc', 'peace', 'peak', 'peck', 'pedagogic', 'pedometer', 'peer', 'peers', 'pejorative', 'peking', 'pelham', 'penetrate', 'peninsula', 'penitentiary', 'pennants', 'pennsylvania', 'people', 'pepsi', 'per', 'perceived', 'percent', 'percentage', 'percieved', 'perfect', 'perfections', 'perfomers', 'perforemed', 'perform', 'performance', 'performances', 'performed', 'performer', 'performers', 'performing', 'performs', 'perfume', 'perfumes', 'perhaps', 'period', 'periods', 'peripherals', 'permanent', 'permitted', 'perpendicular', 'perry', 'person', 'personal', 'personalities', 'personality', 'personally', 'personalty', 'persons', 'perspective', 'persuade', 'perturbed', 'pessimistic', 'peta', 'petech', 'peter', 'petition', 'petitioned', 'petroleum', 'pga', 'phagmodru', 'phagmodrupa', 'phase', 'phased', 'phenomena', 'phenomenon', 'phifer', 'philadelphia', 'phillip', 'phillips', 'philosophical', 'philosophies', 'philosophy', 'phliips', 'phoenix', 'phone', 'phones', 'photos', 'photosynthesis', 'photovoltaic', 'photovoltaics', 'phrase', 'phuntsok', 'physical', 'physician', 'physicians', 'pia', 'pianist', 'pianists', 'piano', 'pick', 'picked', 'pickler', 'picture', 'pictures', 'piece', 'pieces', 'pieter', 'pigs', 'pilot', 'pin', 'pink', 'pinpoint', 'pins', 'pitakas', 'pitchfork', 'pivotal', 'plaaf', 'place', 'placed', 'placement', 'places', 'plan', 'plane', 'planes', 'planet', 'planets', 'planned', 'planning', 'plans', 'plant', 'planted', 'planting', 'plants', 'plastic', 'platform', 'platforms', 'platinum', 'play', 'played', 'player', 'players', 'playing', 'plays', 'plethora', 'pleyel', 'plitical', 'plot', 'poem', 'poes', 'poet', 'point', 'points', 'poisons', 'poland', 'poles', 'police', 'policies', 'policy', 'polish', 'political', 'politically', 'politics', 'poll', 'pollution', 'polonaise', 'polonaises', 'polonasises', 'pond', 'ponds', 'pools', 'poor', 'pop', 'popstars', 'popular', 'popularity', 'populated', 'population', 'populous', 'port', 'portable', 'portals', 'portion', 'portions', 'portrait', 'portraits', 'portray', 'portrayal', 'portrayed', 'portraying', 'portrays', 'pose', 'posed', 'position', 'positive', 'possess', 'possessed', 'possession', 'possibility', 'possible', 'possiblities', 'possibly', 'post', 'posted', 'pot', 'potential', 'potentially', 'power', 'powered', 'powerful', 'powers', 'praag', 'practical', 'practice', 'practiced', 'practices', 'practicing', 'practictioners', 'practised', 'practitioner', 'pragger', 'praise', 'praised', 'prajna', 'prajnaparamita', 'pratityasamutpada', 'pratityasumatupada', 'pratītyasamutpāda', 'prayer', 'pre', 'precarious', 'preceded', 'preceived', 'precept', 'precepts', 'precipitation', 'predict', 'predicted', 'prediction', 'predictions', 'prefer', 'preference', 'pregnancy', 'pregnant', 'prejudice', 'prelate', 'prelates', 'preliminary', 'preludes', 'premier', 'premiere', 'premiered', 'premium', 'preorder', 'preparing', 'presence', 'present', 'presented', 'presenting', 'preserve', 'preserved', 'preserving', 'presided', 'president', 'presidential', 'press', 'pressing', 'pressures', 'presumed', 'prevent', 'prevented', 'prevents', 'preview', 'previews', 'previous', 'previously', 'price', 'prices', 'priciest', 'priciple', 'primarily', 'primary', 'prime', 'prince', 'princes', 'princess', 'principal', 'principles', 'printed', 'prior', 'prison', 'prisoners', 'private', 'privately', 'prix', 'prize', 'probably', 'probation', 'problem', 'problematic', 'problems', 'process', 'processes', 'processing', 'procession', 'processor', 'proclaimed', 'produce', 'produced', 'producer', 'producers', 'produces', 'producing', 'product', 'production', 'productions', 'productive', 'products', 'profession', 'professional', 'professionals', 'professor', 'professors', 'proficiency', 'profiles', 'profit', 'profusely', 'program', 'programming', 'programs', 'progressed', 'progressions', 'prohibition', 'project', 'projectile', 'projects', 'prominent', 'promises', 'promote', 'promoted', 'promotes', 'promoting', 'promotion', 'prompted', 'prone', 'pronounce', 'proof', 'propagated', 'proper', 'property', 'prophesied', 'propose', 'proposed', 'prosecutors', 'protagonist', 'protect', 'protection', 'protectors', 'protest', 'protesting', 'protests', 'prototype', 'proved', 'proves', 'provide', 'provided', 'provides', 'providing', 'province', 'provoked', 'proxy', 'psycho', 'public', 'publication', 'publications', 'publicly', 'publish', 'published', 'publisher', 'publishers', 'publishing', 'puerto', 'pulitzer', 'pulled', 'pump', 'pumped', 'punala', 'punishment', 'pupil', 'purchase', 'purchased', 'purchases', 'pure', 'purification', 'purified', 'purported', 'purpose', 'purposely', 'purposes', 'pursue', 'pursuing', 'pursuit', 'purvis', 'pushed', 'pushing', 'put', 'pv', 'q', 'q1', 'q2', 'q3', 'q4', 'qiang', 'qianhu', 'qianlong', 'qing', 'qingchuan', 'qingguo', 'quada', 'quake', 'quakes', 'qualify', 'qualities', 'quality', 'quantity', 'quantum', 'quarter', 'quarterly', 'queens', 'queensboro', 'quell', 'quest', 'question', 'questioned', 'questions', 'quests', 'quickest', 'quickly', 'quilts', 'quit', 'quote', 'quoted', 'r', 'rabbits', 'rabid', 'race', 'races', 'racial', 'racing', 'racism', 'racist', 'radiation', 'radio', 'radley', 'rage', 'raid', 'raids', 'rail', 'railroad', 'rain', 'rainbow', 'raise', 'raised', 'rally', 'ralph', 'ran', 'ranch', 'randomly', 'randy', 'range', 'ranged', 'rangers', 'rank', 'ranked', 'rankings', 'rant', 'ranting', 'rap', 'rape', 'raped', 'rapid', 'rapper', 'rappers', 'rapping', 'rare', 'rarities', 'rarity', 'rate', 'rated', 'rates', 'rather', 'rating', 'ratings', 'ravaged', 'raw', 'rawski', 'raymond', 'rb', 're', 'reach', 'reached', 'reaching', 'reaction', 'read', 'reader', 'readers', 'reading', 'ready', 'real', 'reality', 'realize', 'realm', 'realms', 'reappointed', 'reason', 'reasons', 'rebirth', 'rebirths', 'reborn', 'rebuild', 'rebuilt', 'recall', 'receive', 'received', 'receives', 'receiving', 'recent', 'recently', 'reception', 'receptionist', 'recharge', 'rechargeable', 'recipient', 'recipients', 'recital', 'recitals', 'recite', 'recited', 'reciting', 'reclaim', 'reclamation', 'recognize', 'recognized', 'recognizes', 'recommend', 'recommendation', 'recommendations', 'recommended', 'reconsider', 'reconstructed', 'record', 'recorded', 'recording', 'recordings', 'records', 'recover', 'recovered', 'recovery', 'recreation', 'recreational', 'recurring', 'red', 'redesigned', 'reduce', 'reduced', 'reduces', 'reduction', 'refer', 'reference', 'referenced', 'references', 'referred', 'referring', 'refine', 'reflect', 'reflected', 'reflector', 'reflects', 'reformed', 'reformer', 'refuge', 'refusal', 'refuse', 'refused', 'refusing', 'regarding', 'regardless', 'regards', 'regent', 'regime', 'reginald', 'region', 'regions', 'registered', 'registration', 'regnal', 'regret', 'regular', 'regularly', 'rehearsal', 'reid', 'reign', 'reigning', 'reject', 'rejected', 'rejects', 'related', 'relates', 'relating', 'relation', 'relations', 'relationship', 'relationships', 'relatives', 'relay', 'release', 'released', 'releases', 'reliable', 'relief', 'religion', 'religions', 'religious', 'reload', 'relocate', 'reluctantly', 'relude', 'rely', 'remain', 'remainder', 'remained', 'remake', 'remark', 'remaster', 'remastered', 'remember', 'remind', 'reminds', 'remote', 'removal', 'remove', 'removed', 'removing', 'renamed', 'rendition', 'renewable', 'renown', 'renunciation', 'reopen', 'reorganization', 'repair', 'replace', 'replaceable', 'replaced', 'replacement', 'replenish', 'replicas', 'reply', 'report', 'reported', 'reportedly', 'reporter', 'reporters', 'reporting', 'reports', 'represent', 'representation', 'representative', 'representatives', 'represented', 'reprinting', 'reprised', 'republic', 'republican', 'request', 'requests', 'require', 'required', 'rescue', 'rescued', 'research', 'researcher', 'researchers', 'reserve', 'reserved', 'reservists', 'resettle', 'reside', 'residence', 'residential', 'residents', 'residue', 'resolution', 'resolve', 'resolving', 'resort', 'resource', 'resources', 'respect', 'respond', 'response', 'responsible', 'rest', 'restaurant', 'restaurants', 'restore', 'restored', 'result', 'resulted', 'resulting', 'results', 'resurrects', 'retailer', 'retouched', 'retreat', 'retrieve', 'return', 'returned', 'returning', 'reveal', 'revealed', 'revealing', 'revenue', 'revenues', 'revere', 'review', 'reviewer', 'reviewers', 'reviews', 'revival', 'revived', 'revolution', 'revolutionary', 'revolutionizing', 'reward', 'reworking', 'rhenish', 'rhythm', 'riaa', 'rican', 'rich', 'richard', 'richie', 'rick', 'rickey', 'rid', 'ride', 'riders', 'riding', 'right', 'rights', 'rinbung', 'rinpungpa', 'riots', 'rise', 'riser', 'rises', 'rishis', 'risk', 'ritual', 'rival', 'river', 'riverbank', 'riverdale', 'rivers', 'rmember', 'roach', 'road', 'roadways', 'roberson', 'robert', 'robertson', 'robinson', 'roc', 'rock', 'rockaway', 'rockstar', 'rod', 'rode', 'rodriguez', 'rods', 'role', 'roles', 'roll', 'rolling', 'rolpe', 'romantic', 'rome', 'roofs', 'room', 'rooms', 'roosevelt', 'root', 'rooted', 'roots', 'rose', 'roseland', 'rosemary', 'rosen', 'rosenberg', 'rotational', 'rotten', 'rough', 'roughly', 'round', 'rounds', 'route', 'routes', 'row', 'rowhouse', 'rowland', 'royal', 'royalty', 'rubato', 'rubble', 'ruben', 'rubin', 'rudimentary', 'ruin', 'ruining', 'rule', 'ruled', 'ruler', 'rules', 'ruling', 'rumor', 'rumored', 'run', 'runner', 'runs', 'rupa', 'rupert', 'rupture', 'rural', 'rush', 'rushfield', 'russian', 'ryan', 's', 'sacrifice', 'sacrifices', 'saddest', 'safe', 'safehouse', 'safety', 'said', 'sailed', 'saiva', 'sakya', 'salary', 'sale', 'sales', 'salinas', 'saline', 'salle', 'salt', 'saltbox', 'salts', 'salvation', 'sam', 'samadhi', 'samadhibhavana', 'samatha', 'same', 'sample', 'samsara', 'samsaric', 'samyaksamadhi', 'san', 'sanbao', 'sanchez', 'sand', 'sands', 'sandy', 'sang', 'sangha', 'sangzao', 'sanjaya', 'sanskrit', 'sarvastivada', 'sasha', 'sat', 'satellite', 'satisfying', 'sato', 'saudi', 'saussure', 'save', 'saved', 'saves', 'saw', 'saxon', 'say', 'saying', 'says', 'scale', 'scaled', 'scandal', 'scattered', 'scenarios', 'scene', 'scenes', 'schadow', 'scheduled', 'scheme', 'scherzos', 'schism', 'schisms', 'schlesinger', 'schol', 'scholarly', 'scholars', 'scholarship', 'scholastic', 'school', 'schoolhouse', 'schoolhouses', 'schoolrooms', 'schools', 'schubert', 'schumann', 'schwarzenegger', 'sciarra', 'science', 'scientific', 'score', 'scores', 'scott', 'scottish', 'scotty', 'scout', 'scrapped', 'screen', 'screened', 'screening', 'screenings', 'screenplay', 'screens', 'scriabin', 'script', 'scripture', 'scriptures', 'sculpted', 'sculptures', 'sdk', 'sea', 'seacrests', 'search', 'searched', 'season', 'seasons', 'seat', 'second', 'secondary', 'secret', 'secretary', 'secrets', 'sectarian', 'section', 'sections', 'sector', 'secure', 'securities', 'security', 'see', 'seeing', 'seek', 'seeking', 'seeks', 'seem', 'seemed', 'seems', 'seen', 'sees', 'seismic', 'seismological', 'seismologist', 'selection', 'selenide', 'self', 'selfless', 'sell', 'selling', 'semi', 'send', 'sense', 'sensors', 'sensory', 'sent', 'sentencing', 'sentient', 'separate', 'separated', 'separates', 'separte', 'seperates', 'september', 'septermber', 'sequel', 'sequence', 'sergei', 'sergel', 'series', 'serious', 'sermons', 'serve', 'served', 'serves', 'service', 'services', 'serving', 'sessions', 'set', 'setting', 'settings', 'settle', 'settled', 'settlement', 'setup', 'seven', 'several', 'severe', 'severine', 'severity', 'sex', 'sexiest', 'sexual', 'shakabpa', 'shakira', 'shaming', 'shan', 'shanghai', 'shania', 'shankun', 'shantideva', 'shaokun', 'shape', 'share', 'shared', 'shares', 'sharing', 'she', 'sheet', 'shekpa', 'shelter', 'sheriff', 'shield', 'shields', 'shifang', 'shift', 'shines', 'ship', 'shirt', 'shirtwaist', 'shock', 'shocks', 'shoddily', 'shoddy', 'shoe', 'shoes', 'shoot', 'shooting', 'shoots', 'shopping', 'shops', 'short', 'shortened', 'shortly', 'shot', 'should', 'show', 'showcase', 'showed', 'showing', 'showings', 'shown', 'shows', 'shramanas', 'shrines', 'shuart', 'shuffle', 'shuman', 'shut', 'shākya', 'si', 'sibling', 'siblings', 'sichuan', 'sick', 'siddhartha', 'siddhārtha', 'side', 'sides', 'sighting', 'sights', 'sigma', 'sign', 'signatures', 'signed', 'significance', 'significant', 'significantly', 'signing', 'signs', 'sila', 'silence', 'silicon', 'silk', 'silver', 'similar', 'similiar', 'simon', 'simplistic', 'simply', 'simulate', 'sin', 'since', 'sing', 'singer', 'singerdancers', 'singers', 'singing', 'single', 'singles', 'singular', 'sinhalese', 'sinopec', 'sister', 'sisters', 'sit', 'sitcom', 'site', 'sites', 'situ', 'situation', 'six', 'sixth', 'size', 'skekpa', 'sketch', 'skill', 'skilled', 'skills', 'skin', 'skirt', 'skit', 'sky', 'skyfall', 'skyscrapers', 'slam', 'slang', 'slated', 'slave', 'slaveholders', 'slavery', 'slaves', 'sleep', 'slides', 'slight', 'slip', 'slippage', 'slocum', 'slowed', 'small', 'smallest', 'snowfall', 'so', 'soccer', 'social', 'societies', 'society', 'socrate', 'soda', 'soft', 'software', 'soka', 'solace', 'solange', 'solar', 'sold', 'soldered', 'soldiers', 'sole', 'solid', 'solo', 'soloist', 'solve', 'solznic', 'some', 'someone', 'something', 'sometimes', 'somewhat', 'son', 'sonam', 'sonata', 'song', 'songs', 'songwriter', 'songwriters', 'songwriting', 'sonnet', 'sony', 'soon', 'sort', 'sought', 'soul', 'sould', 'sound', 'sounds', 'soundtrack', 'sountrack', 'source', 'sources', 'south', 'southern', 'southwestern', 'sovereign', 'sovereignty', 'space', 'spaces', 'span', 'spanish', 'spark', 'sparked', 'sparking', 'sparks', 'spawned', 'speak', 'speaker', 'speaking', 'speaks', 'spec', 'special', 'specialization', 'specialized', 'specialty', 'specific', 'specifically', 'spectre', 'speculate', 'speculated', 'speculation', 'speech', 'speed', 'spend', 'spent', 'sperling', 'spirit', 'spirits', 'spiritual', 'split', 'spoke', 'spoken', 'spokespeople', 'spokesperson', 'sponsored', 'sponsors', 'sponsorship', 'spontaneous', 'spoof', 'sport', 'sporting', 'sports', 'spot', 'spots', 'spouse', 'spread', 'spring', 'springboard', 'square', 'sravasti', 'sri', 'stabilisation', 'stabilization', 'stablished', 'stadium', 'stadiums', 'staff', 'stafford', 'stage', 'stages', 'staging', 'staked', 'stamp', 'stamps', 'stand', 'standard', 'standardize', 'standards', 'standing', 'stands', 'star', 'staring', 'starred', 'stars', 'start', 'started', 'starting', 'starts', 'startup', 'starwave', 'state', 'stated', 'statement', 'statements', 'staten', 'states', 'station', 'stationed', 'stations', 'statistical', 'statue', 'status', 'stay', 'stayed', 'staying', 'steed', 'steel', 'steet', 'step', 'stephanie', 'stereo', 'steve', 'steven', 'stewart', 'sthaviras', 'stickball', 'sticking', 'still', 'sting', 'stirling', 'stock', 'stone', 'stones', 'stonewall', 'stop', 'stopped', 'storable', 'storage', 'store', 'stored', 'stores', 'stories', 'story', 'storyline', 'straight', 'stranded', 'strange', 'strasberg', 'streaming', 'street', 'streets', 'strength', 'strengthen', 'strengthened', 'stresses', 'stretch', 'stretched', 'stricken', 'strict', 'strictest', 'strictly', 'strife', 'strike', 'stripper', 'strong', 'stronger', 'strongest', 'strongly', 'struck', 'structure', 'structured', 'structures', 'struggle', 'struggles', 'studdard', 'student', 'students', 'studied', 'studies', 'studio', 'studios', 'study', 'studying', 'stunt', 'stuntman', 'stupas', 'stuyvesant', 'style', 'styles', 'subcontinent', 'subject', 'subjects', 'submit', 'subplot', 'subsequent', 'substandard', 'substitution', 'subtropical', 'suburbs', 'subway', 'success', 'successful', 'succession', 'successor', 'such', 'suddhodana', 'sued', 'suffer', 'suffered', 'suffering', 'suffers', 'suga', 'suggest', 'suggested', 'suggests', 'suicide', 'suit', 'suite', 'suited', 'summer', 'summers', 'summertime', 'summit', 'sun', 'sunday', 'sung', 'sunlight', 'sunny', 'sunshine', 'sunyata', 'super', 'superbowl', 'superior', 'supervised', 'supplies', 'supply', 'support', 'supported', 'supporting', 'supports', 'supposed', 'supposedly', 'supreme', 'sure', 'surface', 'surfaced', 'surgeries', 'surgery', 'surpass', 'surpassed', 'surprise', 'surprisingly', 'surrender', 'surrounding', 'survey', 'survive', 'survived', 'survivied', 'surviving', 'survivor', 'survivors', 'suspended', 'suspension', 'sutra', 'sutras', 'swaminathan', 'swan', 'swann', 'swayed', 'swhat', 'swift', 'swimsuit', 'swish', 'switch', 'switzerland', 'sword', 'symbol', 'symbolic', 'symbolically', 'symbollically', 'symbols', 'sync', 'synchronize', 'synonym', 'synonymous', 'system', 'systematic', 'systems', 'szafarnia', 'sī', 't', 'tabloid', 'tai', 'taipei', 'taiwan', 'take', 'taken', 'takes', 'taking', 'talent', 'tales', 'talk', 'talked', 'talks', 'tall', 'tally', 'tammany', 'tamyra', 'tang', 'tangjia', 'tangs', 'tanner', 'tantra', 'target', 'targeted', 'targeting', 'tasked', 'tasks', 'tate', 'tathagatagarbha', 'tathgatagarbha', 'taught', 'tax', 'taxes', 'taxicabs', 'taylor', 'teach', 'teacher', 'teachers', 'teaching', 'teachings', 'team', 'teams', 'tease', 'teaser', 'tech', 'technique', 'techniques', 'technological', 'technologies', 'technology', 'teenager', 'tele', 'telecommunications', 'telegraph', 'telephone', 'teleport', 'televised', 'television', 'televsion', 'tell', 'tempations', 'temperature', 'temperatures', 'temperley', 'temple', 'temptations', 'ten', 'tend', 'tenets', 'tennis', 'tentative', 'tenth', 'tents', 'terawatts', 'term', 'terminal', 'terminate', 'terminates', 'terms', 'terrain', 'terrawatts', 'territory', 'terrorist', 'terrorists', 'test', 'testing', 'tetris', 'text', 'texts', 'textures', 'th', 'thames', 'than', 'thanksgiving', 'that', 'the', 'theater', 'theaters', 'theatre', 'theatrical', 'theavoidance', 'theft', 'their', 'theirs', 'them', 'theme', 'themes', 'themselves', 'then', 'theories', 'theorized', 'theory', 'therapy', 'theravada', 'theravadins', 'there', 'thermal', 'thermochemical', 'thervada', 'these', 'they', 'thieves', 'thing', 'things', 'think', 'third', 'thirteen', 'thirteenth', 'this', 'thomas', 'thorn', 'thoroughfare', 'those', 'though', 'thought', 'thousands', 'threat', 'threaten', 'threatened', 'threats', 'three', 'thriller', 'throgs', 'throne', 'through', 'throughout', 'thunderball', 'thursday', 'thus', 'tiananmen', 'tiber', 'tibet', 'tibetan', 'tibetans', 'tibeto', 'tibetologist', 'tibetology', 'ticket', 'tickets', 'tidal', 'tie', 'tied', 'ties', 'til', 'till', 'timbre', 'time', 'times', 'timing', 'tinted', 'tipitaka', 'tisch', 'title', 'titled', 'titles', 'tj', 'to', 'today', 'todt', 'together', 'told', 'tom', 'tomatoes', 'tomboy', 'tombstone', 'tone', 'too', 'took', 'tool', 'top', 'topic', 'topper', 'toppers', 'topping', 'toppman', 'topshop', 'topshops', 'torch', 'tore', 'tortures', 'toscano', 'total', 'totaling', 'totten', 'touch', 'tour', 'tourism', 'tourists', 'tournament', 'tours', 'towards', 'tower', 'towers', 'town', 'townspeople', 'toy', 'traced', 'track', 'tracks', 'trade', 'traded', 'trademark', 'trademarked', 'trades', 'trading', 'tradition', 'traditionally', 'traditions', 'traffic', 'tragic', 'trailer', 'train', 'training', 'trait', 'trammell', 'tramway', 'trand', 'tranquility', 'transfer', 'transferring', 'transform', 'transformations', 'transit', 'transitional', 'translate', 'translated', 'translation', 'translations', 'transliterate', 'transliteration', 'transmitted', 'transmitter', 'transpired', 'transportable', 'transportation', 'trap', 'travel', 'travelers', 'travels', 'treated', 'treaties', 'treatises', 'treatment', 'treaty', 'tree', 'trees', 'tremor', 'trend', 'trial', 'triangle', 'tribal', 'tribe', 'tribune', 'tributaries', 'tribute', 'tried', 'trigger', 'trip', 'trips', 'troops', 'trouble', 'troubles', 'true', 'truly', 'truman', 'trust', 'trusted', 'truth', 'truths', 'truts', 'try', 'trying', 'tsang', 'tsangpa', 'tsar', 'tsongkhapa', 'tto', 'tudor', 'tumed', 'tune', 'tunnel', 'turn', 'turned', 'tutored', 'tv', 'twain', 'tweet', 'tweets', 'twelfth', 'twelve', 'twentieth', 'twice', 'twilight', 'twisted', 'twitter', 'two', 'tyler', 'tyme', 'type', 'typeface', 'types', 'typical', 'typically', 'töregene', 'tümed', 'u', 'u2', 'uhi', 'uk', 'ulcerative', 'ulrich', 'ultimate', 'ultimately', 'un', 'unaccounted', 'unattainable', 'unawakend', 'unborn', 'unchanging', 'uncharacteristic', 'uncovering', 'under', 'understand', 'understanding', 'understood', 'undertake', 'undertook', 'underwent', 'underwood', 'unearthed', 'unease', 'unexpectedly', 'unfair', 'unfavorably', 'unfinished', 'unglazed', 'unhappiness', 'unharmed', 'unicef', 'unicom', 'unifying', 'uninsured', 'unintentionally', 'unionize', 'unique', 'uniqueness', 'unisphere', 'unit', 'united', 'units', 'universal', 'universally', 'universes', 'universities', 'university', 'universitytechnion', 'unknowingly', 'unlike', 'unlikely', 'unlivable', 'unlock', 'unmanned', 'unmarried', 'unnecessary', 'unprecedented', 'unpublished', 'unsatisfactoriness', 'unseat', 'unsuccessfully', 'until', 'untranslated', 'unusable', 'unveil', 'unveiled', 'unwholesome', 'up', 'upanishadic', 'upanishads', 'upgrades', 'upload', 'upon', 'upper', 'uprising', 'upset', 'upstream', 'urban', 'urbanised', 'urbans', 'urged', 'urgent', 'us', 'us21', 'usa', 'usable', 'usage', 'usb', 'use', 'used', 'user', 'users', 'uses', 'usgs', 'using', 'usually', 'utilize', 'utilized', 'vacated', 'vacation', 'vaisnava', 'vajradhara', 'vajrayana', 'valldemossa', 'valley', 'valse', 'value', 'valued', 'van', 'vandalism', 'vapor', 'variation', 'variety', 'various', 'vasquez', 'vassal', 'veda', 'vedic', 'vegas', 'vehicle', 'vehicles', 'velvety', 'vendors', 'venerate', 'veneration', 'venture', 'venturing', 'venue', 'verified', 'verizon', 'verrazzano', 'versatile', 'verses', 'version', 'versions', 'versus', 'vertical', 'vertigo', 'very', 'vh1', 'via', 'viardot', 'vice', 'viceregal', 'victims', 'victory', 'video', 'videos', 'vienna', 'view', 'viewed', 'viewers', 'viewing', 'viewpoint', 'views', 'village', 'villagers', 'vinaya', 'vinnie', 'vinters', 'violating', 'violent', 'violin', 'vipaka', 'vipassana', 'visibly', 'vision', 'visit', 'visited', 'visiting', 'visitors', 'visits', 'visual', 'vma', 'vmas', 'vocal', 'vocalist', 'vogue', 'voice', 'voiced', 'volume', 'vompared', 'vote', 'voted', 'voters', 'votes', 'voting', 'vow', 'vowed', 'vu', 'vulnerability', 'w', 'wade', 'wadsworth', 'wage', 'wages', 'wait', 'waker', 'waldorf', 'walk', 'walkable', 'walking', 'walks', 'wall', 'walls', 'waltz', 'waltzes', 'wanamaker', 'wanda', 'wang', 'wanhu', 'wanli', 'want', 'wanted', 'wants', 'war', 'warder', 'warm', 'warmer', 'warn', 'warned', 'warner', 'warnings', 'warsaw', 'warwick', 'was', 'washington', 'wasmost', 'watch', 'watched', 'watchman', 'water', 'watershed', 'wave', 'waves', 'wax', 'way', 'ways', 'we', 'weak', 'weapon', 'weapons', 'wearing', 'weather', 'web', 'weblog', 'website', 'websites', 'wed', 'wedding', 'wednesday', 'week', 'weekend', 'weekends', 'weekly', 'weeks', 'wei', 'weizmann', 'welcome', 'welcomes', 'well', 'wen', 'wenchuan', 'went', 'wenyao', 'were', 'west', 'western', 'wgwg', 'wha', 'what', 'whats', 'wheel', 'when', 'where', 'whether', 'whic', 'which', 'while', 'white', 'whites', 'who', 'whole', 'whom', 'whos', 'whose', 'whre', 'why', 'wi', 'wide', 'widely', 'wider', 'widespread', 'widow', 'widowhood', 'wield', 'wii', 'wild', 'wildcard', 'wildcards', 'wildlife', 'wilhelm', 'will', 'william', 'williams', 'win', 'wind', 'windows', 'winehouse', 'winfrey', 'winner', 'winners', 'winning', 'wins', 'winter', 'wire', 'wireless', 'wish', 'wisom', 'with', 'within', 'withother', 'without', 'wnyc', 'wodzińska', 'wodziński', 'wolf', 'woman', 'women', 'won', 'wooden', 'woodlands', 'woolf', 'woolworth', 'word', 'words', 'work', 'worked', 'worker', 'workers', 'working', 'works', 'workshops', 'world', 'worlds', 'worldwide', 'worse', 'worst', 'worth', 'worthy', 'would', 'woulday', 'wouldeja', 'woyciechowski', 'wreath', 'wreck', 'write', 'writer', 'writers', 'writing', 'written', 'wrote', 'wswimming', 'wyckoff', 'x75', 'x75s', 'xia', 'xian', 'xinhua', 'xuezhong', 'yagi', 'yang', 'yao', 'ye', 'year', 'yearly', 'years', 'yeezus', 'yeezy', 'yellow', 'yeshes', 'yet', 'ying', 'yingxiu', 'yiu', 'yoga', 'yogacarins', 'yogic', 'yongle', 'yonten', 'york', 'yorker', 'yorkers', 'yorkese', 'you', 'young', 'younger', 'youngest', 'yourself', 'youtube', 'yuan', 'yuanzhang', 'yuji', 'yung', 'z', 'zant', 'zealand', 'zelda', 'zeldatwilight', 'zen', 'zenger', 'zeppelin', 'zhengde', 'zhengtong', 'zhi', 'zhiping', 'zhu', 'zip', 'zipingpu', 'zone', 'zoras', 'zuccotti', 'zywny', 'é', 'étude', 'études', 'ögedei', 'ü', 'ārūpyadhātu', 'łyszczyński', 'śuddhodana', 'śuddhāvāsa', 'żywny', '–', '❤']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_features_dict = dict(\n",
        "    [(token, i) for i, token in enumerate(input_tokens)])\n",
        "target_features_dict = dict(\n",
        "    [(token, i) for i, token in enumerate(target_tokens)])\n",
        "\n",
        "reverse_input_features_dict = dict(\n",
        "    (i, token) for token, i in input_features_dict.items())\n",
        "reverse_target_features_dict = dict(\n",
        "    (i, token) for token, i in target_features_dict.items())\n"
      ],
      "metadata": {
        "id": "eJETxSij9_6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\n",
        "max_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "\n",
        "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
        "    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n",
        "        #Assign 1. for the current line, timestep, & word in encoder_input_data\n",
        "        encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n",
        "    \n",
        "    for timestep, token in enumerate(target_doc.split()):\n",
        "        decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n",
        "        if timestep > 0:\n",
        "            decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1.\n",
        "\n"
      ],
      "metadata": {
        "id": "2pNrP3GQ-CAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\n",
        "max_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_docs), max_encoder_seq_length), dtype='int32'\n",
        ")\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_docs), max_decoder_seq_length), dtype='int32'\n",
        ")\n",
        "decoder_output_data = np.zeros(\n",
        "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='int32'\n",
        "  )\n",
        "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
        "  for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n",
        "    encoder_input_data[line, timestep] = input_features_dict[token]\n",
        "  for timestep, token in enumerate(target_doc.split()):\n",
        "    decoder_input_data[line, timestep] = target_features_dict[token]\n",
        "    if timestep > 0:\n",
        "        decoder_output_data[line, timestep - 1, target_features_dict[token]] = 1.\n"
      ],
      "metadata": {
        "id": "gXoAGWJczutm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers , activations , models , preprocessing"
      ],
      "metadata": {
        "id": "RhLK9E2xxUj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "encoder_inputs = tf.keras.layers.Input(shape=( max_encoder_seq_length, ))\n",
        "encoder_embedding = tf.keras.layers.Embedding( num_encoder_tokens, 200 , mask_zero=True) (encoder_inputs)\n",
        "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 200 , return_state=True )( encoder_embedding )\n",
        "encoder_states = [ state_h , state_c ]\n",
        "\n",
        "decoder_inputs = tf.keras.layers.Input(shape=( None ,  ))\n",
        "decoder_embedding = tf.keras.layers.Embedding( num_decoder_tokens, 200 , mask_zero=True) (decoder_inputs)\n",
        "decoder_lstm = tf.keras.layers.LSTM( 200 , return_state=True , return_sequences=True )\n",
        "decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
        "decoder_dense = tf.keras.layers.Dense( num_decoder_tokens , activation=tf.keras.activations.softmax ) \n",
        "output = decoder_dense ( decoder_outputs )\n",
        "\n",
        "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='categorical_crossentropy')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "tumQUl9lvZMs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0c7f3e3-b8dd-4e4b-e13b-db0185c9b03b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 30)]         0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 30, 200)      1285400     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 200)    984200      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 200),        320800      ['embedding[0][0]']              \n",
            "                                 (None, 200),                                                     \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 200),  320800      ['embedding_1[0][0]',            \n",
            "                                 (None, 200),                     'lstm[0][1]',                   \n",
            "                                 (None, 200)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 4921)   989121      ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,900,321\n",
            "Trainable params: 3,900,321\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size=50, epochs=500 ) \n",
        "model.save( 'model.h5' ) "
      ],
      "metadata": {
        "id": "2yQB-PSwyjgZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba649243-96e6-4d76-acc8-3c85cc5e30dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "120/120 [==============================] - 37s 222ms/step - loss: 5.0124\n",
            "Epoch 2/500\n",
            "120/120 [==============================] - 16s 135ms/step - loss: 4.6280\n",
            "Epoch 3/500\n",
            "120/120 [==============================] - 14s 119ms/step - loss: 4.6007\n",
            "Epoch 4/500\n",
            "120/120 [==============================] - 15s 125ms/step - loss: 4.5664\n",
            "Epoch 5/500\n",
            "120/120 [==============================] - 14s 117ms/step - loss: 4.5376\n",
            "Epoch 6/500\n",
            "120/120 [==============================] - 14s 115ms/step - loss: 4.5061\n",
            "Epoch 7/500\n",
            "120/120 [==============================] - 14s 118ms/step - loss: 4.4792\n",
            "Epoch 8/500\n",
            "120/120 [==============================] - 14s 119ms/step - loss: 4.4585\n",
            "Epoch 9/500\n",
            "120/120 [==============================] - 15s 123ms/step - loss: 4.4320\n",
            "Epoch 10/500\n",
            "120/120 [==============================] - 14s 112ms/step - loss: 4.4008\n",
            "Epoch 11/500\n",
            "120/120 [==============================] - 14s 116ms/step - loss: 4.3625\n",
            "Epoch 12/500\n",
            "120/120 [==============================] - 13s 111ms/step - loss: 4.3174\n",
            "Epoch 13/500\n",
            "120/120 [==============================] - 13s 110ms/step - loss: 4.2847\n",
            "Epoch 14/500\n",
            "120/120 [==============================] - 14s 116ms/step - loss: 4.2535\n",
            "Epoch 15/500\n",
            "120/120 [==============================] - 14s 115ms/step - loss: 4.2335\n",
            "Epoch 16/500\n",
            "120/120 [==============================] - 14s 113ms/step - loss: 4.2100\n",
            "Epoch 17/500\n",
            "120/120 [==============================] - 14s 120ms/step - loss: 4.1881\n",
            "Epoch 18/500\n",
            "120/120 [==============================] - 13s 111ms/step - loss: 4.1791\n",
            "Epoch 19/500\n",
            "120/120 [==============================] - 14s 113ms/step - loss: 4.1564\n",
            "Epoch 20/500\n",
            "120/120 [==============================] - 14s 115ms/step - loss: 4.1437\n",
            "Epoch 21/500\n",
            "120/120 [==============================] - 13s 109ms/step - loss: 4.1290\n",
            "Epoch 22/500\n",
            "120/120 [==============================] - 14s 116ms/step - loss: 4.1127\n",
            "Epoch 23/500\n",
            "120/120 [==============================] - 14s 115ms/step - loss: 4.0954\n",
            "Epoch 24/500\n",
            "120/120 [==============================] - 13s 107ms/step - loss: 4.0845\n",
            "Epoch 25/500\n",
            "120/120 [==============================] - 13s 109ms/step - loss: 4.0665\n",
            "Epoch 26/500\n",
            "120/120 [==============================] - 14s 116ms/step - loss: 4.0501\n",
            "Epoch 27/500\n",
            "120/120 [==============================] - 14s 118ms/step - loss: 4.0303\n",
            "Epoch 28/500\n",
            "120/120 [==============================] - 14s 115ms/step - loss: 4.0185\n",
            "Epoch 29/500\n",
            "120/120 [==============================] - 13s 110ms/step - loss: 3.9945\n",
            "Epoch 30/500\n",
            "120/120 [==============================] - 14s 116ms/step - loss: 3.9788\n",
            "Epoch 31/500\n",
            "120/120 [==============================] - 13s 112ms/step - loss: 3.9621\n",
            "Epoch 32/500\n",
            "120/120 [==============================] - 14s 113ms/step - loss: 3.9436\n",
            "Epoch 33/500\n",
            "120/120 [==============================] - 13s 111ms/step - loss: 3.9249\n",
            "Epoch 34/500\n",
            "120/120 [==============================] - 14s 117ms/step - loss: 3.9081\n",
            "Epoch 35/500\n",
            "120/120 [==============================] - 14s 114ms/step - loss: 3.8938\n",
            "Epoch 36/500\n",
            "120/120 [==============================] - 13s 111ms/step - loss: 3.8735\n",
            "Epoch 37/500\n",
            "120/120 [==============================] - 14s 115ms/step - loss: 3.8526\n",
            "Epoch 38/500\n",
            "120/120 [==============================] - 15s 121ms/step - loss: 3.8318\n",
            "Epoch 39/500\n",
            "120/120 [==============================] - 14s 115ms/step - loss: 3.8182\n",
            "Epoch 40/500\n",
            "120/120 [==============================] - 13s 111ms/step - loss: 3.8021\n",
            "Epoch 41/500\n",
            "120/120 [==============================] - 14s 116ms/step - loss: 3.7862\n",
            "Epoch 42/500\n",
            "120/120 [==============================] - 14s 113ms/step - loss: 3.7661\n",
            "Epoch 43/500\n",
            "120/120 [==============================] - 13s 112ms/step - loss: 3.7515\n",
            "Epoch 44/500\n",
            "120/120 [==============================] - 14s 116ms/step - loss: 3.7348\n",
            "Epoch 45/500\n",
            "120/120 [==============================] - 14s 113ms/step - loss: 3.7209\n",
            "Epoch 46/500\n",
            "120/120 [==============================] - 14s 113ms/step - loss: 3.7006\n",
            "Epoch 47/500\n",
            "120/120 [==============================] - 15s 122ms/step - loss: 3.6806\n",
            "Epoch 48/500\n",
            "120/120 [==============================] - 14s 115ms/step - loss: 3.6709\n",
            "Epoch 49/500\n",
            "120/120 [==============================] - 14s 113ms/step - loss: 3.6503\n",
            "Epoch 50/500\n",
            "120/120 [==============================] - 14s 114ms/step - loss: 3.6368\n",
            "Epoch 51/500\n",
            "120/120 [==============================] - 14s 114ms/step - loss: 3.6178\n",
            "Epoch 52/500\n",
            "120/120 [==============================] - 14s 114ms/step - loss: 3.6027\n",
            "Epoch 53/500\n",
            "120/120 [==============================] - 14s 114ms/step - loss: 3.5854\n",
            "Epoch 54/500\n",
            "120/120 [==============================] - 13s 110ms/step - loss: 3.5698\n",
            "Epoch 55/500\n",
            "120/120 [==============================] - 14s 114ms/step - loss: 3.5534\n",
            "Epoch 56/500\n",
            "120/120 [==============================] - 14s 116ms/step - loss: 3.5365\n",
            "Epoch 57/500\n",
            "120/120 [==============================] - 13s 110ms/step - loss: 3.5186\n",
            "Epoch 58/500\n",
            "120/120 [==============================] - 14s 115ms/step - loss: 3.5068\n",
            "Epoch 59/500\n",
            "120/120 [==============================] - 13s 108ms/step - loss: 3.4845\n",
            "Epoch 60/500\n",
            "120/120 [==============================] - 13s 111ms/step - loss: 3.4702\n",
            "Epoch 61/500\n",
            "120/120 [==============================] - 14s 115ms/step - loss: 3.4554\n",
            "Epoch 62/500\n",
            "120/120 [==============================] - 13s 111ms/step - loss: 3.4371\n",
            "Epoch 63/500\n",
            "120/120 [==============================] - 14s 116ms/step - loss: 3.4157\n",
            "Epoch 64/500\n",
            " 17/120 [===>..........................] - ETA: 11s - loss: 3.3242"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_inference_models():\n",
        "    \n",
        "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
        "    \n",
        "    decoder_state_input_h = tf.keras.layers.Input(shape=( 200 ,))\n",
        "    decoder_state_input_c = tf.keras.layers.Input(shape=( 200 ,))\n",
        "    \n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "    \n",
        "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "        decoder_embedding , initial_state=decoder_states_inputs)\n",
        "    decoder_states = [state_h, state_c]\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    decoder_model = tf.keras.models.Model(\n",
        "        [decoder_inputs] + decoder_states_inputs,\n",
        "        [decoder_outputs] + decoder_states)\n",
        "    \n",
        "    return encoder_model , decoder_model"
      ],
      "metadata": {
        "id": "ji7gtBAGA2FK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def str_to_tokens( sentence : str ):\n",
        "    words = sentence.lower().split()\n",
        "    tokens_list = list()\n",
        "    for word in words:\n",
        "        tokens_list.append( input_features_dict[word] ) \n",
        "    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=max_encoder_seq_length , padding='post')"
      ],
      "metadata": {
        "id": "q3ABM4cLv2i7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "buOhn3r2qJlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc_model , dec_model = make_inference_models()\n",
        "\n",
        "for _ in range(10):\n",
        "    states_values = enc_model.predict( str_to_tokens( input( 'Enter question : ' ) ) )\n",
        "    empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
        "    empty_target_seq[0, 0] = target_features_dict['<START>']\n",
        "    stop_condition = False\n",
        "    decoded_translation = ''\n",
        "    while not stop_condition :\n",
        "        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n",
        "        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
        "        sampled_word = reverse_target_features_dict[sampled_word_index]\n",
        "        decoded_translation += \" \" + sampled_word\n",
        "        \n",
        "        if sampled_word == '<END>' or len(decoded_translation.split()) > max_decoder_seq_length:\n",
        "            stop_condition = True\n",
        "            \n",
        "        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
        "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
        "        states_values = [ h , c ] \n",
        "\n",
        "    print( decoded_translation )\n"
      ],
      "metadata": {
        "id": "WaFfdY7dA4Do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "training_model = load_model('model.h5')\n",
        "\n",
        "encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
        "    \n",
        "decoder_state_input_h = tf.keras.layers.Input(shape=( 200 ,))\n",
        "decoder_state_input_c = tf.keras.layers.Input(shape=( 200 ,))\n",
        "\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_embedding , initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = tf.keras.models.Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "def decode_response(test_input):\n",
        "  states_values = encoder_model.predict(test_input)\n",
        "\n",
        "  target_seq = np.zeros( ( 1 , 1 ) )\n",
        "  target_seq[0, 0] = target_features_dict['<START>']\n",
        "  stop_condition = False\n",
        "  decoded_translation = \"\"\n",
        "  while not stop_condition :\n",
        "      dec_outputs , h , c = training_model.predict([ target_seq ] + states_values )\n",
        "\n",
        "      sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
        "      sampled_word = reverse_target_features_dict[sampled_word_index]\n",
        "      decoded_translation += \" \" + sampled_word\n",
        "      \n",
        "      if sampled_word == '<END>' or len(decoded_translation.split()) > max_decoder_seq_length:\n",
        "          stop_condition = True\n",
        "          \n",
        "      empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
        "      empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
        "      states_values = [ h , c ] \n",
        "\n",
        "  return decoded_translation\n"
      ],
      "metadata": {
        "id": "NstOScMC4gNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(input):\n",
        "  input = clean_text(input)\n",
        "  #tokens = re.findall(r\"[\\w']+|[^\\s\\w]\", input)\n",
        "  #input_matrix = np.zeros(\n",
        "  #    (1, max_encoder_seq_length),\n",
        "  #    dtype='int32')\n",
        "  #for timestep, token in enumerate(tokens):\n",
        "  #  if token in input_features_dict:\n",
        "  #    input_matrix[0, timestep] = input_features_dict[token]\n",
        "  #output = decode_response(input_matrix)\n",
        "  output = decode_response(str_to_tokens(input))\n",
        "  return output.replace(\"<START>\",\"\").replace(\"<END>\",\"\")\n",
        "\n",
        "\n",
        "while True:\n",
        "  reply = input()\n",
        "  if reply == \"STOP\":\n",
        "    break\n",
        "  print(generate_response(reply))"
      ],
      "metadata": {
        "id": "_9iOubyS5hZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_inference_models():\n",
        "    \n",
        "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
        "    \n",
        "    decoder_state_input_h = tf.keras.layers.Input(shape=( 200 ,))\n",
        "    decoder_state_input_c = tf.keras.layers.Input(shape=( 200 ,))\n",
        "    \n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "    \n",
        "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "        decoder_embedding , initial_state=decoder_states_inputs)\n",
        "    decoder_states = [state_h, state_c]\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    decoder_model = tf.keras.models.Model(\n",
        "        [decoder_inputs] + decoder_states_inputs,\n",
        "        [decoder_outputs] + decoder_states)\n",
        "    \n",
        "    return encoder_model , decoder_model"
      ],
      "metadata": {
        "id": "AIYzszCnvZEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Legacy Code:"
      ],
      "metadata": {
        "id": "4XZz5wLBvZpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "#Dimensionality\n",
        "dimensionality = 256\n",
        "\n",
        "#The batch size and number of epochs\n",
        "batch_size = 10\n",
        "epochs = 10\n",
        "\n",
        "#Encoder\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder_lstm = LSTM(dimensionality, return_state=True)\n",
        "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [state_hidden, state_cell]\n",
        "\n",
        "#Decoder\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = LSTM(dimensionality, return_sequences=True, return_state=True)\n",
        "decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "#Model\n",
        "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "#Compiling\n",
        "training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')\n",
        "\n",
        "#Training\n",
        "training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = epochs, validation_split = 0.2)\n",
        "training_model.save('training_model.h5')\n",
        "     "
      ],
      "metadata": {
        "id": "m_gkMmTxBpYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "training_model = load_model('training_model.h5')\n",
        "encoder_inputs = training_model.input[0]\n",
        "encoder_outputs, state_h_enc, state_c_enc = training_model.layers[2].output\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "latent_dim = 256\n",
        "decoder_state_input_hidden = Input(shape=(latent_dim,))\n",
        "decoder_state_input_cell = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]\n",
        "decoder_outputs, state_hidden, state_cell = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_hidden, state_cell]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
        "\n",
        "def decode_response(test_input):\n",
        "  #Getting the output states to pass into the decoder\n",
        "  states_value = encoder_model.predict(test_input)\n",
        "  \n",
        "  #Generating empty target sequence of length 1\n",
        "  target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "  \n",
        "  #Setting the first token of target sequence with the start token\n",
        "  target_seq[0, 0, target_features_dict['<START>']] = 1.\n",
        "  \n",
        "  #A variable to store our response word by word\n",
        "  decoded_sentence = ''\n",
        "    \n",
        "  stop_condition = False\n",
        "\n",
        "  while not stop_condition:\n",
        "    #Predicting output tokens with probabilities and states\n",
        "    output_tokens, hidden_state, cell_state = decoder_model.predict([target_seq] + states_value)\n",
        "    \n",
        "    #Choosing the one with highest probability\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_token = reverse_target_features_dict[sampled_token_index]\n",
        "    decoded_sentence += \" \" + sampled_token\n",
        "    \n",
        "    #Stop if hit max length or found the stop token\n",
        "    if (sampled_token == '' or len(decoded_sentence) > max_decoder_seq_length):\n",
        "      stop_condition = True\n",
        "    \n",
        "    #Update the target sequence\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    target_seq[0, 0, sampled_token_index] = 1.\n",
        "    \n",
        "    #Update states\n",
        "    states_value = [hidden_state, cell_state]\n",
        "  return decoded_sentence\n",
        "     \n"
      ],
      "metadata": {
        "id": "YxHAc3HInCwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatBot:\n",
        "  negative_responses = (\"no\", \"nope\", \"nah\", \"naw\", \"not a chance\", \"sorry\")\n",
        "  exit_commands = (\"quit\", \"pause\", \"exit\", \"goodbye\", \"bye\", \"later\", \"stop\")\n",
        "  \n",
        "  #Method to start the conversation\n",
        "  def start_chat(self):\n",
        "    user_response = input(\"Hi, I'm a chatbot trained on random dialogs. Would you like to chat with me?\\n\")\n",
        "    \n",
        "    if user_response in self.negative_responses:\n",
        "      print(\"Ok, have a great day!\")\n",
        "      return\n",
        "    self.chat(user_response)\n",
        "  \n",
        "  #Method to handle the conversation\n",
        "  def chat(self, reply):\n",
        "    while not self.make_exit(reply):\n",
        "      reply = input(self.generate_response(reply)+\"\\n\")\n",
        "    \n",
        "  #Method to convert user input into a matrix\n",
        "  def string_to_matrix(self, user_input):\n",
        "    tokens = re.findall(r\"[\\w']+|[^\\s\\w]\", user_input)\n",
        "    user_input_matrix = np.zeros(\n",
        "      (1, max_encoder_seq_length, num_encoder_tokens),\n",
        "      dtype='float32')\n",
        "    for timestep, token in enumerate(tokens):\n",
        "      if token in input_features_dict:\n",
        "        user_input_matrix[0, timestep, input_features_dict[token]] = 1.\n",
        "    return user_input_matrix\n",
        "\n",
        "  #Method that will create a response using seq2seq model we built\n",
        "  def generate_response(self, user_input):\n",
        "    input_matrix = self.string_to_matrix(user_input)  \n",
        "    chatbot_response = decode_response(input_matrix)\n",
        "    #Remove  and  tokens from chatbot_response\n",
        "    chatbot_response = chatbot_response.replace(\"<START>\",'')\n",
        "    chatbot_response = chatbot_response.replace(\"<END>\",'')\n",
        "    return chatbot_response\n",
        "  \n",
        "  #Method to check for exit commands\n",
        "  def make_exit(self, reply):\n",
        "    for exit_command in self.exit_commands:\n",
        "      if exit_command in reply:\n",
        "        print(\"Ok, have a great day!\")\n",
        "        return True\n",
        "    return False\n",
        "  \n",
        "chatbot = ChatBot()\n",
        "chatbot.start_chat()"
      ],
      "metadata": {
        "id": "32bUse3SnSoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(input):\n",
        "  input = clean_text(input)\n",
        "  tokens = re.findall(r\"[\\w']+|[^\\s\\w]\", input)\n",
        "  input_matrix = np.zeros(\n",
        "      (1, max_encoder_seq_length, num_encoder_tokens),\n",
        "      dtype='float32')\n",
        "  for timestep, token in enumerate(tokens):\n",
        "    if token in input_features_dict:\n",
        "      input_matrix[0, timestep, input_features_dict[token]] = 1\n",
        "  output = decode_response(input_matrix)\n",
        "  return output.replace(\"<START>\",\"\").replace(\"<END>\",\"\")\n",
        "\n",
        "\n",
        "while True:\n",
        "  reply = input()\n",
        "  if reply == \"STOP\":\n",
        "    break\n",
        "  print(generate_response(reply)+'\\n')"
      ],
      "metadata": {
        "id": "_IIiglHk1nK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model):\n",
        "  model.save('')\n",
        "  return pick_model"
      ],
      "metadata": {
        "id": "wrLd7rHuDWvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model():\n",
        "  return model"
      ],
      "metadata": {
        "id": "BIYi2NhSDigl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}